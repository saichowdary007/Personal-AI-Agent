# LLM Assistant

![Python](https://img.shields.io/badge/Python-3.9%2B-blue?logo=python)
![FastAPI](https://img.shields.io/badge/FastAPI-async-green?logo=fastapi)
![Google Gemini](https://img.shields.io/badge/Gemini-API-yellow?logo=google)

A modern, full-stack AI-powered personal assistant built with **FastAPI** (Python backend) and **Next.js** (React frontend). This assistant leverages Google Gemini for natural language processing and provides productivity tools in a beautiful web UI.

---

## âœ¨ Features
- **Conversational Chat**: Natural, context-aware chat with AI
- **Summarization**: Summarize long texts and documents
- **Email Drafting**: Generate professional emails from prompts
- **Todo Management**: Manage tasks and to-do lists
- **Code Assistance**: Explain, debug, and generate code
- **Translation**: Translate text between languages

## ğŸ› ï¸ Tech Stack
- **Backend**: Python, FastAPI, Google Gemini API
- **Frontend**: Next.js (React), modern CSS

## ğŸš€ Getting Started

### 1. Clone the repository
```bash
git clone <your-repo-url>
cd <project-folder>
```

### 2. Backend Setup
Install dependencies:
```bash
pip install -r requirements.txt
```

Create a `.env` file with your Google Gemini API key:
```env
GOOGLE_GEMINI_API_KEY=your_gemini_api_key
```

Run the backend:
```bash
uvicorn main:app --reload
```

### 3. Frontend Setup
If you have a Next.js frontend, install dependencies and run:
```bash
npm install
npm run dev
```

## ğŸ”‘ Environment Variables
- `GOOGLE_GEMINI_API_KEY` â€“ Your Google Gemini API key (required for backend)

## ğŸ“š Usage
1. Open the frontend in your browser (usually [http://localhost:3000](http://localhost:3000)).
2. Sign in with your credentials.
3. Use the sidebar to access Chat, Summarize, Email, Todo, Code, or Translate features.

## ğŸ§© API Endpoints
- `POST /assist`: Main endpoint for all assistant features. Supports types: `summarize`, `email`, `todo`, `code`, `translate`, `chat`.
- `POST /token`: Obtain an authentication token.
- `GET /health`: Health check endpoint.

## ğŸ“ Project Structure
```
llm_assistant/
â”œâ”€â”€ main.py               # FastAPI app
â”œâ”€â”€ services/             # Core service modules
â”œâ”€â”€ components/           # React components (frontend)
â”œâ”€â”€ pages/                # Next.js pages (frontend)
â”œâ”€â”€ utils/                # Utility modules
â”œâ”€â”€ data/                 # Data storage
â”œâ”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ package.json          # Frontend dependencies
â”œâ”€â”€ .env                  # Environment variables
â””â”€â”€ README.md             # Documentation
```

## ğŸ¤ Contributing
Pull requests are welcome! For major changes, please open an issue first to discuss what you would like to change.

## ğŸ“„ License
MIT

---
**Built with â¤ï¸ using FastAPI, Next.js, and Google Gemini.**

â”œâ”€â”€ utils/               # Utility functions
â”œâ”€â”€ data/               # Data storage
â”œâ”€â”€ requirements.txt    # Dependencies
â””â”€â”€ README.md          # Documentation
```

## API Endpoints

- `POST /assist`: Main endpoint for all assistant features
- Supports multiple types: summarize, email, todo, code, translate, chat

## Configuration

Create a `.env` file with your API keys:
```
OPENAI_API_KEY=your_key_here
``` 