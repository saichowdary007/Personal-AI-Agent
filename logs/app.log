{"timestamp": "2025-04-16T18:04:49.909372", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 110}
{"timestamp": "2025-04-16T18:04:49.915261", "level": "INFO", "message": "LLM client closed.", "module": "main", "function": "shutdown_event", "line": 112}
{"timestamp": "2025-04-16T18:10:54.345606", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 110}
{"timestamp": "2025-04-16T18:10:54.355371", "level": "INFO", "message": "LLM client closed.", "module": "main", "function": "shutdown_event", "line": 112}
{"timestamp": "2025-04-16T18:14:49.416928", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 110}
{"timestamp": "2025-04-16T18:14:49.419998", "level": "INFO", "message": "LLM client closed.", "module": "main", "function": "shutdown_event", "line": 112}
{"timestamp": "2025-04-16T18:15:00.890155", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 111}
{"timestamp": "2025-04-16T18:15:00.897413", "level": "INFO", "message": "LLM client closed.", "module": "main", "function": "shutdown_event", "line": 113}
{"timestamp": "2025-04-16T18:22:41.314734", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-16T18:22:45.610499", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-16T18:27:38.263315", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-16T18:27:40.046496", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-16T18:35:01.560208", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-16T18:35:01.560502", "level": "INFO", "message": "Processing chat with input: hi", "module": "chat", "function": "process", "line": 15}
{"timestamp": "2025-04-16T18:35:02.598483", "level": "INFO", "message": "Chat response generated via LLMClient.", "module": "chat", "function": "process", "line": 32}
{"timestamp": "2025-04-16T18:35:02.598742", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-16T18:36:44.658506", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-16T18:36:44.658849", "level": "INFO", "message": "Processing chat with input: hi", "module": "chat", "function": "process", "line": 15}
{"timestamp": "2025-04-16T18:36:45.704540", "level": "INFO", "message": "Chat response generated via LLMClient.", "module": "chat", "function": "process", "line": 32}
{"timestamp": "2025-04-16T18:36:45.704682", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-16T18:38:17.514583", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-16T18:38:25.409648", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-16T18:41:06.754123", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-16T18:41:06.754734", "level": "INFO", "message": "Processing chat with input: hi", "module": "chat", "function": "process", "line": 15}
{"timestamp": "2025-04-16T18:41:07.608620", "level": "INFO", "message": "Chat response generated via LLMClient.", "module": "chat", "function": "process", "line": 32}
{"timestamp": "2025-04-16T18:41:07.608883", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-16T18:43:40.524713", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-16T18:43:40.525583", "level": "INFO", "message": "Processing chat with input: hi", "module": "chat", "function": "process", "line": 15}
{"timestamp": "2025-04-16T18:43:42.655101", "level": "INFO", "message": "Chat response generated via LLMClient.", "module": "chat", "function": "process", "line": 32}
{"timestamp": "2025-04-16T18:43:42.655912", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-16T18:55:35.855225", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-16T18:55:35.861626", "level": "ERROR", "message": "Error during LLMClient summarization: 'LLMClient' object has no attribute 'model_name'", "module": "summarize", "function": "process", "line": 86, "exception": "Traceback (most recent call last):\n  File \"/Users/simba/Downloads/Personal AI Agent/services/summarize.py\", line 47, in process\n    model = parameters.get(\"model\", self.llm_client.model_name) if parameters else self.llm_client.model_name\nAttributeError: 'LLMClient' object has no attribute 'model_name'"}
{"timestamp": "2025-04-16T18:55:35.862051", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-16T18:56:01.676265", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-16T18:56:01.676568", "level": "INFO", "message": "Processing chat with input: hi", "module": "chat", "function": "process", "line": 15}
{"timestamp": "2025-04-16T18:56:03.062611", "level": "INFO", "message": "Chat response generated via LLMClient.", "module": "chat", "function": "process", "line": 32}
{"timestamp": "2025-04-16T18:56:03.063082", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-16T18:56:29.038814", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-16T18:56:37.879683", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-16T18:56:55.444137", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-16T18:56:58.525331", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-16T18:57:10.002423", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-16T18:57:19.817974", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-16T19:04:15.030101", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 111}
{"timestamp": "2025-04-16T19:04:15.030627", "level": "INFO", "message": "LLM client closed.", "module": "main", "function": "shutdown_event", "line": 113}
{"timestamp": "2025-04-16T19:04:16.307890", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 111}
{"timestamp": "2025-04-16T19:04:16.311444", "level": "INFO", "message": "LLM client closed.", "module": "main", "function": "shutdown_event", "line": 113}
{"timestamp": "2025-04-16T19:20:00.014475", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-16T19:20:04.239015", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-16T19:20:46.463956", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-16T19:20:50.411465", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-16T20:25:50.778088", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 111}
{"timestamp": "2025-04-16T20:25:50.778789", "level": "INFO", "message": "LLM client closed.", "module": "main", "function": "shutdown_event", "line": 113}
{"timestamp": "2025-04-16T20:26:31.489583", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-16T20:26:39.584941", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-16T20:27:03.843335", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-16T20:27:06.548827", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-18T21:00:39.679269", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-18T21:00:49.889457", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-18T21:01:00.334101", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-18T21:01:00.334236", "level": "INFO", "message": "Processing chat with input: hello", "module": "chat", "function": "process", "line": 15}
{"timestamp": "2025-04-18T21:01:01.352278", "level": "INFO", "message": "Chat response generated via LLMClient.", "module": "chat", "function": "process", "line": 32}
{"timestamp": "2025-04-18T21:01:01.352343", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-18T21:01:11.597685", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-18T21:01:11.597856", "level": "INFO", "message": "Processing chat with input: 6 times 52", "module": "chat", "function": "process", "line": 15}
{"timestamp": "2025-04-18T21:01:12.648473", "level": "INFO", "message": "Chat response generated via LLMClient.", "module": "chat", "function": "process", "line": 32}
{"timestamp": "2025-04-18T21:01:12.648546", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-18T21:03:25.399347", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 111}
{"timestamp": "2025-04-18T21:03:25.400033", "level": "INFO", "message": "LLM client closed.", "module": "main", "function": "shutdown_event", "line": 113}
{"timestamp": "2025-04-18T21:20:31.078540", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 111}
{"timestamp": "2025-04-18T21:20:31.083847", "level": "INFO", "message": "LLM client closed.", "module": "main", "function": "shutdown_event", "line": 113}
{"timestamp": "2025-04-18T21:20:47.909607", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-18T21:20:47.909684", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-18T21:20:58.830774", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-18T21:20:58.830930", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-18T21:21:04.986910", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-18T21:21:04.987071", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-18T21:21:19.747107", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-18T21:21:26.688252", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-18T21:22:12.488647", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 111}
{"timestamp": "2025-04-18T21:22:12.488953", "level": "INFO", "message": "LLM client closed.", "module": "main", "function": "shutdown_event", "line": 113}
{"timestamp": "2025-04-18T21:22:22.643084", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 111}
{"timestamp": "2025-04-18T21:22:22.647689", "level": "INFO", "message": "LLM client closed.", "module": "main", "function": "shutdown_event", "line": 113}
{"timestamp": "2025-04-18T21:22:29.787375", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-18T21:22:29.787467", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-18T21:22:35.751449", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-18T21:22:44.292815", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-18T21:24:10.992047", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-18T21:24:10.992318", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-18T21:24:19.538127", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-18T21:24:22.190577", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-18T21:26:07.242914", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-18T21:26:07.243129", "level": "INFO", "message": "Processing chat with input: odd numbers  in python", "module": "chat", "function": "process", "line": 15}
{"timestamp": "2025-04-18T21:26:09.607949", "level": "INFO", "message": "Chat response generated via LLMClient.", "module": "chat", "function": "process", "line": 32}
{"timestamp": "2025-04-18T21:26:09.608561", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-18T21:27:31.971469", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 111}
{"timestamp": "2025-04-18T21:27:31.973045", "level": "INFO", "message": "LLM client closed.", "module": "main", "function": "shutdown_event", "line": 113}
{"timestamp": "2025-04-18T21:27:39.569142", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 111}
{"timestamp": "2025-04-18T21:27:39.571371", "level": "INFO", "message": "LLM client closed.", "module": "main", "function": "shutdown_event", "line": 113}
{"timestamp": "2025-04-18T21:27:56.289627", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-18T21:27:56.289711", "level": "INFO", "message": "Processing chat with input: even numbers in python", "module": "chat", "function": "process", "line": 15}
{"timestamp": "2025-04-18T21:28:00.043678", "level": "INFO", "message": "Chat response generated via LLMClient.", "module": "chat", "function": "process", "line": 32}
{"timestamp": "2025-04-18T21:28:00.043926", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-18T21:31:06.257221", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-18T21:31:10.731153", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-18T21:31:49.132199", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 111}
{"timestamp": "2025-04-18T21:31:49.133156", "level": "INFO", "message": "LLM client closed.", "module": "main", "function": "shutdown_event", "line": 113}
{"timestamp": "2025-04-18T21:35:21.647776", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 111}
{"timestamp": "2025-04-18T21:35:21.656120", "level": "INFO", "message": "LLM client closed.", "module": "main", "function": "shutdown_event", "line": 113}
{"timestamp": "2025-04-18T21:36:18.498747", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 112}
{"timestamp": "2025-04-18T21:36:18.502637", "level": "INFO", "message": "LLM client closed.", "module": "main", "function": "shutdown_event", "line": 114}
{"timestamp": "2025-04-18T21:38:03.561364", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 112}
{"timestamp": "2025-04-18T21:38:03.562060", "level": "INFO", "message": "LLM client closed.", "module": "main", "function": "shutdown_event", "line": 114}
{"timestamp": "2025-04-18T21:40:22.515275", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-18T21:40:22.515350", "level": "INFO", "message": "Processing chat with input: hi", "module": "chat", "function": "process", "line": 15}
{"timestamp": "2025-04-18T21:40:23.527857", "level": "INFO", "message": "Chat response generated via LLMClient.", "module": "chat", "function": "process", "line": 32}
{"timestamp": "2025-04-18T21:40:23.527932", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-18T21:40:30.111736", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-18T21:40:30.111974", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-18T21:40:42.937131", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-18T21:40:50.463251", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-18T21:41:05.290189", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-18T21:41:07.661178", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-18T22:15:49.649451", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 112}
{"timestamp": "2025-04-18T22:15:49.650228", "level": "INFO", "message": "LLM client closed.", "module": "main", "function": "shutdown_event", "line": 114}
{"timestamp": "2025-04-18T22:16:24.022472", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-18T22:16:28.513581", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-18T22:17:32.677041", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 112}
{"timestamp": "2025-04-18T22:17:32.677302", "level": "INFO", "message": "LLM client closed.", "module": "main", "function": "shutdown_event", "line": 114}
{"timestamp": "2025-04-18T22:17:34.624837", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 112}
{"timestamp": "2025-04-18T22:17:34.629546", "level": "INFO", "message": "LLM client closed.", "module": "main", "function": "shutdown_event", "line": 114}
{"timestamp": "2025-04-18T22:21:53.120074", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-18T22:21:53.120153", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-18T22:22:00.474858", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-18T22:22:07.551407", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-18T22:23:13.092411", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-18T22:23:16.888077", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-18T22:23:37.391551", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-18T22:23:39.161326", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-18T22:23:57.534554", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-18T22:24:06.992306", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-18T22:56:59.692717", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 112}
{"timestamp": "2025-04-18T22:56:59.693700", "level": "INFO", "message": "LLM client closed.", "module": "main", "function": "shutdown_event", "line": 114}
{"timestamp": "2025-04-21T17:07:03.488648", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 112}
{"timestamp": "2025-04-21T17:07:03.497703", "level": "INFO", "message": "LLM client closed.", "module": "main", "function": "shutdown_event", "line": 114}
{"timestamp": "2025-04-21T17:09:31.856296", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 112}
{"timestamp": "2025-04-21T17:09:31.866458", "level": "INFO", "message": "LLM client closed.", "module": "main", "function": "shutdown_event", "line": 114}
{"timestamp": "2025-04-21T17:13:00.837387", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 112}
{"timestamp": "2025-04-21T17:13:00.838447", "level": "INFO", "message": "LLM client closed.", "module": "main", "function": "shutdown_event", "line": 114}
{"timestamp": "2025-04-21T17:18:45.928080", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 112}
{"timestamp": "2025-04-21T17:18:45.936161", "level": "INFO", "message": "LLM client closed.", "module": "main", "function": "shutdown_event", "line": 114}
{"timestamp": "2025-04-21T17:38:11.366541", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 112}
{"timestamp": "2025-04-21T17:38:11.375726", "level": "INFO", "message": "LLM client closed.", "module": "main", "function": "shutdown_event", "line": 114}
{"timestamp": "2025-04-21T17:41:11.675875", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 112}
{"timestamp": "2025-04-21T17:41:11.676642", "level": "INFO", "message": "LLM client closed.", "module": "main", "function": "shutdown_event", "line": 114}
{"timestamp": "2025-04-21T17:49:35.867660", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 112}
{"timestamp": "2025-04-21T17:49:35.867905", "level": "INFO", "message": "LLM client closed.", "module": "main", "function": "shutdown_event", "line": 114}
{"timestamp": "2025-04-21T17:53:01.913233", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 112}
{"timestamp": "2025-04-21T17:53:01.917509", "level": "INFO", "message": "LLM client closed.", "module": "main", "function": "shutdown_event", "line": 114}
{"timestamp": "2025-04-21T19:39:04.809934", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 112}
{"timestamp": "2025-04-21T19:39:04.819090", "level": "INFO", "message": "LLM client closed.", "module": "main", "function": "shutdown_event", "line": 114}
{"timestamp": "2025-04-21T20:40:41.850492", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 112}
{"timestamp": "2025-04-21T20:40:41.854909", "level": "INFO", "message": "LLM client closed.", "module": "main", "function": "shutdown_event", "line": 114}
{"timestamp": "2025-04-21T20:41:50.670668", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 112}
{"timestamp": "2025-04-21T20:41:50.672466", "level": "INFO", "message": "LLM client closed.", "module": "main", "function": "shutdown_event", "line": 114}
{"timestamp": "2025-04-21T21:22:52.290212", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-21T21:22:52.291203", "level": "INFO", "message": "Processing chat with input: hello", "module": "chat", "function": "process", "line": 15}
{"timestamp": "2025-04-21T21:23:02.754878", "level": "ERROR", "message": "Error during LLMClient chat processing: RetryError[<Future at 0x1118617c0 state=finished raised Exception>]", "module": "chat", "function": "process", "line": 48, "exception": "Traceback (most recent call last):\n  File \"/Users/simba/Downloads/Personal AI Agent/utils/llm_client.py\", line 57, in generate_response\n    \"content\": data[\"choices\"][0][\"message\"][\"content\"],\nKeyError: 'choices'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/simba/Downloads/Personal AI Agent/utils/llm_client.py\", line 76, in generate_response\n    local_response.raise_for_status()\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/httpx/_models.py\", line 829, in raise_for_status\n    raise HTTPStatusError(message, request=request, response=self)\nhttpx.HTTPStatusError: Client error '404 Not Found' for url 'http://localhost:11434/api/generate'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n    result = await fn(*args, **kwargs)\n  File \"/Users/simba/Downloads/Personal AI Agent/utils/llm_client.py\", line 85, in generate_response\n    raise Exception(\"Both OpenRouter and local fallback failed.\")\nException: Both OpenRouter and local fallback failed.\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/Users/simba/Downloads/Personal AI Agent/services/chat.py\", line 24, in process\n    response = await self.llm_client.generate_response(\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n    return await copy(fn, *args, **kwargs)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n    do = await self.iter(retry_state=retry_state)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/tenacity/__init__.py\", line 421, in exc_check\n    raise retry_exc from fut.exception()\ntenacity.RetryError: RetryError[<Future at 0x1118617c0 state=finished raised Exception>]"}
{"timestamp": "2025-04-21T21:23:02.755231", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-21T21:43:25.374428", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 112}
{"timestamp": "2025-04-21T21:43:25.376721", "level": "INFO", "message": "LLM client closed.", "module": "main", "function": "shutdown_event", "line": 114}
{"timestamp": "2025-04-21T21:51:25.169318", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-21T21:51:25.169402", "level": "INFO", "message": "Processing chat with input: hello", "module": "chat", "function": "process", "line": 15}
{"timestamp": "2025-04-21T21:51:38.373117", "level": "ERROR", "message": "Error during LLMClient chat processing: RetryError[<Future at 0x1055f4e50 state=finished raised Exception>]", "module": "chat", "function": "process", "line": 48, "exception": "Traceback (most recent call last):\n  File \"/Users/simba/Downloads/Personal AI Agent/utils/llm_client.py\", line 57, in generate_response\n    \"content\": data[\"choices\"][0][\"message\"][\"content\"],\nKeyError: 'choices'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/simba/Downloads/Personal AI Agent/utils/llm_client.py\", line 76, in generate_response\n    local_response.raise_for_status()\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/httpx/_models.py\", line 829, in raise_for_status\n    raise HTTPStatusError(message, request=request, response=self)\nhttpx.HTTPStatusError: Client error '404 Not Found' for url 'http://localhost:11434/api/generate'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n    result = await fn(*args, **kwargs)\n  File \"/Users/simba/Downloads/Personal AI Agent/utils/llm_client.py\", line 85, in generate_response\n    raise Exception(\"Both OpenRouter and local fallback failed.\")\nException: Both OpenRouter and local fallback failed.\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/Users/simba/Downloads/Personal AI Agent/services/chat.py\", line 24, in process\n    response = await self.llm_client.generate_response(\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n    return await copy(fn, *args, **kwargs)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n    do = await self.iter(retry_state=retry_state)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/tenacity/__init__.py\", line 421, in exc_check\n    raise retry_exc from fut.exception()\ntenacity.RetryError: RetryError[<Future at 0x1055f4e50 state=finished raised Exception>]"}
{"timestamp": "2025-04-21T21:51:38.373541", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-21T22:14:30.841923", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 112}
{"timestamp": "2025-04-21T22:14:30.843263", "level": "INFO", "message": "LLM client closed.", "module": "main", "function": "shutdown_event", "line": 114}
{"timestamp": "2025-04-22T02:35:44.733695", "level": "INFO", "message": "Starting LLM Assistant API", "module": "main", "function": "<module>", "line": 249}
{"timestamp": "2025-04-22T03:09:04.542013", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-22T03:09:04.542942", "level": "INFO", "message": "Processing chat with input: hi", "module": "chat", "function": "process", "line": 15}
{"timestamp": "2025-04-22T03:09:05.709629", "level": "INFO", "message": "Chat response generated via LLMClient.", "module": "chat", "function": "process", "line": 32}
{"timestamp": "2025-04-22T03:09:05.709762", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-22T03:09:23.473417", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-22T03:09:27.898757", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-22T03:10:05.743443", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-22T03:10:14.391769", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-22T03:10:29.707910", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-22T03:10:31.902124", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-22T03:10:41.890942", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-22T03:10:42.422069", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-22T03:11:29.827855", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-22T03:11:30.402333", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-22T03:11:40.931302", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-22T03:11:41.888035", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-22T04:32:08.286385", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 112}
{"timestamp": "2025-04-22T04:32:08.287936", "level": "INFO", "message": "LLM client closed.", "module": "main", "function": "shutdown_event", "line": 114}
{"timestamp": "2025-04-22T04:32:09.361581", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 222}
{"timestamp": "2025-04-22T04:32:41.831739", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 228}
{"timestamp": "2025-04-22T04:32:41.835050", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 230}
{"timestamp": "2025-04-22T04:32:42.859696", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 222}
{"timestamp": "2025-04-22T14:52:18.809048", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 222}
{"timestamp": "2025-04-22T20:42:21.438686", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 222}
{"timestamp": "2025-04-22T20:42:35.205303", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 228}
{"timestamp": "2025-04-22T20:42:35.208815", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 230}
{"timestamp": "2025-04-22T20:42:35.899094", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 222}
{"timestamp": "2025-04-22T20:43:13.730539", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 228}
{"timestamp": "2025-04-22T20:43:13.734614", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 230}
{"timestamp": "2025-04-22T20:43:17.133413", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 222}
{"timestamp": "2025-04-22T20:44:24.327584", "level": "WARNING", "message": "Failed login attempt for user: fgf", "module": "main", "function": "login_for_access_token", "line": 281}
{"timestamp": "2025-04-22T20:44:24.327812", "level": "INFO", "message": "Request: POST /token - Time: 0.0017s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T20:47:19.637200", "level": "INFO", "message": "Successful login for user: testuser", "module": "main", "function": "login_for_access_token", "line": 288}
{"timestamp": "2025-04-22T20:47:19.646930", "level": "INFO", "message": "Request: POST /token - Time: 0.2667s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T20:47:27.326418", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-22T20:47:29.229631", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-22T20:47:29.826082", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-22T20:47:30.088273", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-22T20:47:30.309386", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-22T20:47:30.541202", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-22T20:47:37.527239", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-22T20:47:37.528889", "level": "INFO", "message": "Request: POST /assist - Time: 7.2204s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T20:47:37.532058", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-22T20:47:38.281571", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-22T20:47:38.282064", "level": "INFO", "message": "Request: POST /assist - Time: 10.9641s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T20:47:38.288609", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-22T20:47:39.041261", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-22T20:47:39.041709", "level": "INFO", "message": "Request: POST /assist - Time: 9.8145s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T20:47:39.045676", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-22T20:47:40.482113", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-22T20:47:40.482429", "level": "INFO", "message": "Request: POST /assist - Time: 10.6589s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T20:47:41.458405", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-22T20:47:41.458780", "level": "INFO", "message": "Request: POST /assist - Time: 11.3729s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T20:47:46.264063", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-22T20:47:46.264594", "level": "INFO", "message": "Request: POST /assist - Time: 15.7261s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T20:47:48.417522", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-22T20:47:48.417997", "level": "INFO", "message": "Request: POST /assist - Time: 10.1308s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T20:47:49.135272", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-22T20:47:49.135806", "level": "INFO", "message": "Request: POST /assist - Time: 10.0915s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T20:47:52.280412", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-22T20:47:52.280660", "level": "INFO", "message": "Request: POST /assist - Time: 14.7497s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T20:51:13.974572", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-22T20:51:27.560932", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-22T20:51:27.561457", "level": "INFO", "message": "Request: POST /assist - Time: 13.5896s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T21:01:34.901420", "level": "ERROR", "message": "Error in api", "module": "logger", "function": "log_error", "line": 108, "exception": "  + Exception Group Traceback (most recent call last):\n  |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_utils.py\", line 76, in collapse_excgroups\n  |     yield\n  |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 181, in __call__\n  |     recv_stream.close()\n  |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 772, in __aexit__\n  |     raise BaseExceptionGroup(\n  | exceptiongroup.ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\n  +-+---------------- 1 ----------------\n    | Traceback (most recent call last):\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/errors.py\", line 165, in __call__\n    |     await self.app(scope, receive, _send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/cors.py\", line 93, in __call__\n    |     await self.simple_response(scope, receive, send, request_headers=headers)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/cors.py\", line 144, in simple_response\n    |     await self.app(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 29, in __call__\n    |     await responder(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 126, in __call__\n    |     await super().__call__(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 46, in __call__\n    |     await self.app(scope, receive, self.send_with_compression)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 181, in __call__\n    |     recv_stream.close()\n    |   File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/contextlib.py\", line 135, in __exit__\n    |     self.gen.throw(type, value, traceback)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_utils.py\", line 82, in collapse_excgroups\n    |     raise exc\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 178, in __call__\n    |     response = await self.dispatch_func(request, call_next)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/main.py\", line 145, in __call__\n    |     response = await call_next(request)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 156, in call_next\n    |     raise app_exc\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 141, in coro\n    |     await self.app(scope, receive_or_disconnect, send_no_error)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n    |     await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    |     raise exc\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    |     await app(scope, receive, sender)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 714, in __call__\n    |     await self.middleware_stack(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 734, in app\n    |     await route.handle(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 288, in handle\n    |     await self.app(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 76, in app\n    |     await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    |     raise exc\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    |     await app(scope, receive, sender)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 73, in app\n    |     response = await f(request)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/fastapi/routing.py\", line 301, in app\n    |     raw_response = await run_endpoint_function(\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/fastapi/routing.py\", line 212, in run_endpoint_function\n    |     return await dependant.call(**values)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/main.py\", line 424, in list_todos\n    |     return todo_service.list_tasks(current_user.username)\n    | TypeError: list_tasks() takes 1 positional argument but 2 were given\n    +------------------------------------\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/errors.py\", line 165, in __call__\n    await self.app(scope, receive, _send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/cors.py\", line 93, in __call__\n    await self.simple_response(scope, receive, send, request_headers=headers)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/cors.py\", line 144, in simple_response\n    await self.app(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 29, in __call__\n    await responder(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 126, in __call__\n    await super().__call__(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 46, in __call__\n    await self.app(scope, receive, self.send_with_compression)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 181, in __call__\n    recv_stream.close()\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/contextlib.py\", line 135, in __exit__\n    self.gen.throw(type, value, traceback)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_utils.py\", line 82, in collapse_excgroups\n    raise exc\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 178, in __call__\n    response = await self.dispatch_func(request, call_next)\n  File \"/Users/simba/Downloads/Personal AI Agent/main.py\", line 145, in __call__\n    response = await call_next(request)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 156, in call_next\n    raise app_exc\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 141, in coro\n    await self.app(scope, receive_or_disconnect, send_no_error)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 714, in __call__\n    await self.middleware_stack(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 734, in app\n    await route.handle(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 288, in handle\n    await self.app(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 76, in app\n    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 73, in app\n    response = await f(request)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/fastapi/routing.py\", line 301, in app\n    raw_response = await run_endpoint_function(\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/fastapi/routing.py\", line 212, in run_endpoint_function\n    return await dependant.call(**values)\n  File \"/Users/simba/Downloads/Personal AI Agent/main.py\", line 424, in list_todos\n    return todo_service.list_tasks(current_user.username)\nTypeError: list_tasks() takes 1 positional argument but 2 were given"}
{"timestamp": "2025-04-22T21:01:34.911589", "level": "ERROR", "message": "Error in api", "module": "logger", "function": "log_error", "line": 108, "exception": "  + Exception Group Traceback (most recent call last):\n  |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_utils.py\", line 76, in collapse_excgroups\n  |     yield\n  |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 181, in __call__\n  |     recv_stream.close()\n  |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 772, in __aexit__\n  |     raise BaseExceptionGroup(\n  | exceptiongroup.ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\n  +-+---------------- 1 ----------------\n    | Traceback (most recent call last):\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/errors.py\", line 165, in __call__\n    |     await self.app(scope, receive, _send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/cors.py\", line 93, in __call__\n    |     await self.simple_response(scope, receive, send, request_headers=headers)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/cors.py\", line 144, in simple_response\n    |     await self.app(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 29, in __call__\n    |     await responder(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 126, in __call__\n    |     await super().__call__(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 46, in __call__\n    |     await self.app(scope, receive, self.send_with_compression)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 181, in __call__\n    |     recv_stream.close()\n    |   File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/contextlib.py\", line 135, in __exit__\n    |     self.gen.throw(type, value, traceback)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_utils.py\", line 82, in collapse_excgroups\n    |     raise exc\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 178, in __call__\n    |     response = await self.dispatch_func(request, call_next)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/main.py\", line 145, in __call__\n    |     response = await call_next(request)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 156, in call_next\n    |     raise app_exc\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 141, in coro\n    |     await self.app(scope, receive_or_disconnect, send_no_error)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n    |     await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    |     raise exc\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    |     await app(scope, receive, sender)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 714, in __call__\n    |     await self.middleware_stack(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 734, in app\n    |     await route.handle(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 288, in handle\n    |     await self.app(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 76, in app\n    |     await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    |     raise exc\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    |     await app(scope, receive, sender)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 73, in app\n    |     response = await f(request)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/fastapi/routing.py\", line 301, in app\n    |     raw_response = await run_endpoint_function(\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/fastapi/routing.py\", line 212, in run_endpoint_function\n    |     return await dependant.call(**values)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/main.py\", line 424, in list_todos\n    |     return todo_service.list_tasks(current_user.username)\n    | TypeError: list_tasks() takes 1 positional argument but 2 were given\n    +------------------------------------\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/errors.py\", line 165, in __call__\n    await self.app(scope, receive, _send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/cors.py\", line 93, in __call__\n    await self.simple_response(scope, receive, send, request_headers=headers)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/cors.py\", line 144, in simple_response\n    await self.app(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 29, in __call__\n    await responder(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 126, in __call__\n    await super().__call__(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 46, in __call__\n    await self.app(scope, receive, self.send_with_compression)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 181, in __call__\n    recv_stream.close()\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/contextlib.py\", line 135, in __exit__\n    self.gen.throw(type, value, traceback)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_utils.py\", line 82, in collapse_excgroups\n    raise exc\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 178, in __call__\n    response = await self.dispatch_func(request, call_next)\n  File \"/Users/simba/Downloads/Personal AI Agent/main.py\", line 145, in __call__\n    response = await call_next(request)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 156, in call_next\n    raise app_exc\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 141, in coro\n    await self.app(scope, receive_or_disconnect, send_no_error)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 714, in __call__\n    await self.middleware_stack(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 734, in app\n    await route.handle(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 288, in handle\n    await self.app(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 76, in app\n    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 73, in app\n    response = await f(request)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/fastapi/routing.py\", line 301, in app\n    raw_response = await run_endpoint_function(\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/fastapi/routing.py\", line 212, in run_endpoint_function\n    return await dependant.call(**values)\n  File \"/Users/simba/Downloads/Personal AI Agent/main.py\", line 424, in list_todos\n    return todo_service.list_tasks(current_user.username)\nTypeError: list_tasks() takes 1 positional argument but 2 were given"}
{"timestamp": "2025-04-22T21:01:42.023056", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-22T21:01:54.578578", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-22T21:01:54.579062", "level": "INFO", "message": "Request: POST /assist - Time: 12.5598s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T21:02:01.023958", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-22T21:02:07.608850", "level": "ERROR", "message": "Error in api", "module": "logger", "function": "log_error", "line": 108, "exception": "  + Exception Group Traceback (most recent call last):\n  |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_utils.py\", line 76, in collapse_excgroups\n  |     yield\n  |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 181, in __call__\n  |     recv_stream.close()\n  |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 772, in __aexit__\n  |     raise BaseExceptionGroup(\n  | exceptiongroup.ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\n  +-+---------------- 1 ----------------\n    | Traceback (most recent call last):\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/errors.py\", line 165, in __call__\n    |     await self.app(scope, receive, _send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/cors.py\", line 93, in __call__\n    |     await self.simple_response(scope, receive, send, request_headers=headers)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/cors.py\", line 144, in simple_response\n    |     await self.app(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 29, in __call__\n    |     await responder(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 126, in __call__\n    |     await super().__call__(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 46, in __call__\n    |     await self.app(scope, receive, self.send_with_compression)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 181, in __call__\n    |     recv_stream.close()\n    |   File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/contextlib.py\", line 135, in __exit__\n    |     self.gen.throw(type, value, traceback)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_utils.py\", line 82, in collapse_excgroups\n    |     raise exc\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 178, in __call__\n    |     response = await self.dispatch_func(request, call_next)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/main.py\", line 145, in __call__\n    |     response = await call_next(request)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 156, in call_next\n    |     raise app_exc\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 141, in coro\n    |     await self.app(scope, receive_or_disconnect, send_no_error)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n    |     await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    |     raise exc\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    |     await app(scope, receive, sender)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 714, in __call__\n    |     await self.middleware_stack(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 734, in app\n    |     await route.handle(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 288, in handle\n    |     await self.app(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 76, in app\n    |     await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    |     raise exc\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    |     await app(scope, receive, sender)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 73, in app\n    |     response = await f(request)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/fastapi/routing.py\", line 301, in app\n    |     raw_response = await run_endpoint_function(\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/fastapi/routing.py\", line 212, in run_endpoint_function\n    |     return await dependant.call(**values)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/main.py\", line 424, in list_todos\n    |     return todo_service.list_tasks(current_user.username)\n    | TypeError: list_tasks() takes 1 positional argument but 2 were given\n    +------------------------------------\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/errors.py\", line 165, in __call__\n    await self.app(scope, receive, _send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/cors.py\", line 93, in __call__\n    await self.simple_response(scope, receive, send, request_headers=headers)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/cors.py\", line 144, in simple_response\n    await self.app(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 29, in __call__\n    await responder(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 126, in __call__\n    await super().__call__(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 46, in __call__\n    await self.app(scope, receive, self.send_with_compression)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 181, in __call__\n    recv_stream.close()\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/contextlib.py\", line 135, in __exit__\n    self.gen.throw(type, value, traceback)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_utils.py\", line 82, in collapse_excgroups\n    raise exc\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 178, in __call__\n    response = await self.dispatch_func(request, call_next)\n  File \"/Users/simba/Downloads/Personal AI Agent/main.py\", line 145, in __call__\n    response = await call_next(request)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 156, in call_next\n    raise app_exc\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 141, in coro\n    await self.app(scope, receive_or_disconnect, send_no_error)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 714, in __call__\n    await self.middleware_stack(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 734, in app\n    await route.handle(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 288, in handle\n    await self.app(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 76, in app\n    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 73, in app\n    response = await f(request)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/fastapi/routing.py\", line 301, in app\n    raw_response = await run_endpoint_function(\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/fastapi/routing.py\", line 212, in run_endpoint_function\n    return await dependant.call(**values)\n  File \"/Users/simba/Downloads/Personal AI Agent/main.py\", line 424, in list_todos\n    return todo_service.list_tasks(current_user.username)\nTypeError: list_tasks() takes 1 positional argument but 2 were given"}
{"timestamp": "2025-04-22T21:02:07.618053", "level": "ERROR", "message": "Error in api", "module": "logger", "function": "log_error", "line": 108, "exception": "  + Exception Group Traceback (most recent call last):\n  |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_utils.py\", line 76, in collapse_excgroups\n  |     yield\n  |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 181, in __call__\n  |     recv_stream.close()\n  |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 772, in __aexit__\n  |     raise BaseExceptionGroup(\n  | exceptiongroup.ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\n  +-+---------------- 1 ----------------\n    | Traceback (most recent call last):\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/errors.py\", line 165, in __call__\n    |     await self.app(scope, receive, _send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/cors.py\", line 93, in __call__\n    |     await self.simple_response(scope, receive, send, request_headers=headers)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/cors.py\", line 144, in simple_response\n    |     await self.app(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 29, in __call__\n    |     await responder(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 126, in __call__\n    |     await super().__call__(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 46, in __call__\n    |     await self.app(scope, receive, self.send_with_compression)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 181, in __call__\n    |     recv_stream.close()\n    |   File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/contextlib.py\", line 135, in __exit__\n    |     self.gen.throw(type, value, traceback)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_utils.py\", line 82, in collapse_excgroups\n    |     raise exc\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 178, in __call__\n    |     response = await self.dispatch_func(request, call_next)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/main.py\", line 145, in __call__\n    |     response = await call_next(request)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 156, in call_next\n    |     raise app_exc\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 141, in coro\n    |     await self.app(scope, receive_or_disconnect, send_no_error)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n    |     await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    |     raise exc\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    |     await app(scope, receive, sender)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 714, in __call__\n    |     await self.middleware_stack(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 734, in app\n    |     await route.handle(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 288, in handle\n    |     await self.app(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 76, in app\n    |     await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    |     raise exc\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    |     await app(scope, receive, sender)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 73, in app\n    |     response = await f(request)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/fastapi/routing.py\", line 301, in app\n    |     raw_response = await run_endpoint_function(\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/fastapi/routing.py\", line 212, in run_endpoint_function\n    |     return await dependant.call(**values)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/main.py\", line 424, in list_todos\n    |     return todo_service.list_tasks(current_user.username)\n    | TypeError: list_tasks() takes 1 positional argument but 2 were given\n    +------------------------------------\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/errors.py\", line 165, in __call__\n    await self.app(scope, receive, _send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/cors.py\", line 93, in __call__\n    await self.simple_response(scope, receive, send, request_headers=headers)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/cors.py\", line 144, in simple_response\n    await self.app(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 29, in __call__\n    await responder(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 126, in __call__\n    await super().__call__(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 46, in __call__\n    await self.app(scope, receive, self.send_with_compression)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 181, in __call__\n    recv_stream.close()\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/contextlib.py\", line 135, in __exit__\n    self.gen.throw(type, value, traceback)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_utils.py\", line 82, in collapse_excgroups\n    raise exc\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 178, in __call__\n    response = await self.dispatch_func(request, call_next)\n  File \"/Users/simba/Downloads/Personal AI Agent/main.py\", line 145, in __call__\n    response = await call_next(request)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 156, in call_next\n    raise app_exc\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 141, in coro\n    await self.app(scope, receive_or_disconnect, send_no_error)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 714, in __call__\n    await self.middleware_stack(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 734, in app\n    await route.handle(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 288, in handle\n    await self.app(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 76, in app\n    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 73, in app\n    response = await f(request)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/fastapi/routing.py\", line 301, in app\n    raw_response = await run_endpoint_function(\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/fastapi/routing.py\", line 212, in run_endpoint_function\n    return await dependant.call(**values)\n  File \"/Users/simba/Downloads/Personal AI Agent/main.py\", line 424, in list_todos\n    return todo_service.list_tasks(current_user.username)\nTypeError: list_tasks() takes 1 positional argument but 2 were given"}
{"timestamp": "2025-04-22T21:02:10.063459", "level": "ERROR", "message": "Error in api", "module": "logger", "function": "log_error", "line": 108, "exception": "  + Exception Group Traceback (most recent call last):\n  |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_utils.py\", line 76, in collapse_excgroups\n  |     yield\n  |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 181, in __call__\n  |     recv_stream.close()\n  |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 772, in __aexit__\n  |     raise BaseExceptionGroup(\n  | exceptiongroup.ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\n  +-+---------------- 1 ----------------\n    | Traceback (most recent call last):\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/errors.py\", line 165, in __call__\n    |     await self.app(scope, receive, _send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/cors.py\", line 93, in __call__\n    |     await self.simple_response(scope, receive, send, request_headers=headers)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/cors.py\", line 144, in simple_response\n    |     await self.app(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 29, in __call__\n    |     await responder(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 126, in __call__\n    |     await super().__call__(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 46, in __call__\n    |     await self.app(scope, receive, self.send_with_compression)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 181, in __call__\n    |     recv_stream.close()\n    |   File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/contextlib.py\", line 135, in __exit__\n    |     self.gen.throw(type, value, traceback)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_utils.py\", line 82, in collapse_excgroups\n    |     raise exc\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 178, in __call__\n    |     response = await self.dispatch_func(request, call_next)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/main.py\", line 145, in __call__\n    |     response = await call_next(request)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 156, in call_next\n    |     raise app_exc\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 141, in coro\n    |     await self.app(scope, receive_or_disconnect, send_no_error)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n    |     await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    |     raise exc\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    |     await app(scope, receive, sender)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 714, in __call__\n    |     await self.middleware_stack(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 734, in app\n    |     await route.handle(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 288, in handle\n    |     await self.app(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 76, in app\n    |     await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    |     raise exc\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    |     await app(scope, receive, sender)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 73, in app\n    |     response = await f(request)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/fastapi/routing.py\", line 301, in app\n    |     raw_response = await run_endpoint_function(\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/fastapi/routing.py\", line 212, in run_endpoint_function\n    |     return await dependant.call(**values)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/main.py\", line 424, in list_todos\n    |     return todo_service.list_tasks(current_user.username)\n    | TypeError: list_tasks() takes 1 positional argument but 2 were given\n    +------------------------------------\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/errors.py\", line 165, in __call__\n    await self.app(scope, receive, _send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/cors.py\", line 93, in __call__\n    await self.simple_response(scope, receive, send, request_headers=headers)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/cors.py\", line 144, in simple_response\n    await self.app(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 29, in __call__\n    await responder(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 126, in __call__\n    await super().__call__(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 46, in __call__\n    await self.app(scope, receive, self.send_with_compression)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 181, in __call__\n    recv_stream.close()\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/contextlib.py\", line 135, in __exit__\n    self.gen.throw(type, value, traceback)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_utils.py\", line 82, in collapse_excgroups\n    raise exc\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 178, in __call__\n    response = await self.dispatch_func(request, call_next)\n  File \"/Users/simba/Downloads/Personal AI Agent/main.py\", line 145, in __call__\n    response = await call_next(request)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 156, in call_next\n    raise app_exc\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 141, in coro\n    await self.app(scope, receive_or_disconnect, send_no_error)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 714, in __call__\n    await self.middleware_stack(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 734, in app\n    await route.handle(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 288, in handle\n    await self.app(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 76, in app\n    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 73, in app\n    response = await f(request)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/fastapi/routing.py\", line 301, in app\n    raw_response = await run_endpoint_function(\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/fastapi/routing.py\", line 212, in run_endpoint_function\n    return await dependant.call(**values)\n  File \"/Users/simba/Downloads/Personal AI Agent/main.py\", line 424, in list_todos\n    return todo_service.list_tasks(current_user.username)\nTypeError: list_tasks() takes 1 positional argument but 2 were given"}
{"timestamp": "2025-04-22T21:02:10.072948", "level": "ERROR", "message": "Error in api", "module": "logger", "function": "log_error", "line": 108, "exception": "  + Exception Group Traceback (most recent call last):\n  |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_utils.py\", line 76, in collapse_excgroups\n  |     yield\n  |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 181, in __call__\n  |     recv_stream.close()\n  |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 772, in __aexit__\n  |     raise BaseExceptionGroup(\n  | exceptiongroup.ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\n  +-+---------------- 1 ----------------\n    | Traceback (most recent call last):\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/errors.py\", line 165, in __call__\n    |     await self.app(scope, receive, _send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/cors.py\", line 93, in __call__\n    |     await self.simple_response(scope, receive, send, request_headers=headers)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/cors.py\", line 144, in simple_response\n    |     await self.app(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 29, in __call__\n    |     await responder(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 126, in __call__\n    |     await super().__call__(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 46, in __call__\n    |     await self.app(scope, receive, self.send_with_compression)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 181, in __call__\n    |     recv_stream.close()\n    |   File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/contextlib.py\", line 135, in __exit__\n    |     self.gen.throw(type, value, traceback)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_utils.py\", line 82, in collapse_excgroups\n    |     raise exc\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 178, in __call__\n    |     response = await self.dispatch_func(request, call_next)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/main.py\", line 145, in __call__\n    |     response = await call_next(request)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 156, in call_next\n    |     raise app_exc\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 141, in coro\n    |     await self.app(scope, receive_or_disconnect, send_no_error)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n    |     await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    |     raise exc\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    |     await app(scope, receive, sender)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 714, in __call__\n    |     await self.middleware_stack(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 734, in app\n    |     await route.handle(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 288, in handle\n    |     await self.app(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 76, in app\n    |     await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    |     raise exc\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    |     await app(scope, receive, sender)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 73, in app\n    |     response = await f(request)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/fastapi/routing.py\", line 301, in app\n    |     raw_response = await run_endpoint_function(\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/fastapi/routing.py\", line 212, in run_endpoint_function\n    |     return await dependant.call(**values)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/main.py\", line 424, in list_todos\n    |     return todo_service.list_tasks(current_user.username)\n    | TypeError: list_tasks() takes 1 positional argument but 2 were given\n    +------------------------------------\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/errors.py\", line 165, in __call__\n    await self.app(scope, receive, _send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/cors.py\", line 93, in __call__\n    await self.simple_response(scope, receive, send, request_headers=headers)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/cors.py\", line 144, in simple_response\n    await self.app(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 29, in __call__\n    await responder(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 126, in __call__\n    await super().__call__(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 46, in __call__\n    await self.app(scope, receive, self.send_with_compression)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 181, in __call__\n    recv_stream.close()\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/contextlib.py\", line 135, in __exit__\n    self.gen.throw(type, value, traceback)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_utils.py\", line 82, in collapse_excgroups\n    raise exc\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 178, in __call__\n    response = await self.dispatch_func(request, call_next)\n  File \"/Users/simba/Downloads/Personal AI Agent/main.py\", line 145, in __call__\n    response = await call_next(request)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 156, in call_next\n    raise app_exc\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 141, in coro\n    await self.app(scope, receive_or_disconnect, send_no_error)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 714, in __call__\n    await self.middleware_stack(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 734, in app\n    await route.handle(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 288, in handle\n    await self.app(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 76, in app\n    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 73, in app\n    response = await f(request)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/fastapi/routing.py\", line 301, in app\n    raw_response = await run_endpoint_function(\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/fastapi/routing.py\", line 212, in run_endpoint_function\n    return await dependant.call(**values)\n  File \"/Users/simba/Downloads/Personal AI Agent/main.py\", line 424, in list_todos\n    return todo_service.list_tasks(current_user.username)\nTypeError: list_tasks() takes 1 positional argument but 2 were given"}
{"timestamp": "2025-04-22T21:02:11.066528", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-22T21:02:11.067017", "level": "INFO", "message": "Request: POST /assist - Time: 10.0451s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T21:02:13.595915", "level": "ERROR", "message": "Error in api", "module": "logger", "function": "log_error", "line": 108, "exception": "  + Exception Group Traceback (most recent call last):\n  |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_utils.py\", line 76, in collapse_excgroups\n  |     yield\n  |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 181, in __call__\n  |     recv_stream.close()\n  |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 772, in __aexit__\n  |     raise BaseExceptionGroup(\n  | exceptiongroup.ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\n  +-+---------------- 1 ----------------\n    | Traceback (most recent call last):\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/errors.py\", line 165, in __call__\n    |     await self.app(scope, receive, _send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/cors.py\", line 93, in __call__\n    |     await self.simple_response(scope, receive, send, request_headers=headers)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/cors.py\", line 144, in simple_response\n    |     await self.app(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 29, in __call__\n    |     await responder(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 126, in __call__\n    |     await super().__call__(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 46, in __call__\n    |     await self.app(scope, receive, self.send_with_compression)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 181, in __call__\n    |     recv_stream.close()\n    |   File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/contextlib.py\", line 135, in __exit__\n    |     self.gen.throw(type, value, traceback)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_utils.py\", line 82, in collapse_excgroups\n    |     raise exc\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 178, in __call__\n    |     response = await self.dispatch_func(request, call_next)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/main.py\", line 145, in __call__\n    |     response = await call_next(request)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 156, in call_next\n    |     raise app_exc\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 141, in coro\n    |     await self.app(scope, receive_or_disconnect, send_no_error)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n    |     await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    |     raise exc\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    |     await app(scope, receive, sender)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 714, in __call__\n    |     await self.middleware_stack(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 734, in app\n    |     await route.handle(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 288, in handle\n    |     await self.app(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 76, in app\n    |     await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    |     raise exc\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    |     await app(scope, receive, sender)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 73, in app\n    |     response = await f(request)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/fastapi/routing.py\", line 301, in app\n    |     raw_response = await run_endpoint_function(\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/fastapi/routing.py\", line 212, in run_endpoint_function\n    |     return await dependant.call(**values)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/main.py\", line 424, in list_todos\n    |     return todo_service.list_tasks(current_user.username)\n    | TypeError: list_tasks() takes 1 positional argument but 2 were given\n    +------------------------------------\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/errors.py\", line 165, in __call__\n    await self.app(scope, receive, _send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/cors.py\", line 93, in __call__\n    await self.simple_response(scope, receive, send, request_headers=headers)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/cors.py\", line 144, in simple_response\n    await self.app(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 29, in __call__\n    await responder(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 126, in __call__\n    await super().__call__(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 46, in __call__\n    await self.app(scope, receive, self.send_with_compression)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 181, in __call__\n    recv_stream.close()\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/contextlib.py\", line 135, in __exit__\n    self.gen.throw(type, value, traceback)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_utils.py\", line 82, in collapse_excgroups\n    raise exc\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 178, in __call__\n    response = await self.dispatch_func(request, call_next)\n  File \"/Users/simba/Downloads/Personal AI Agent/main.py\", line 145, in __call__\n    response = await call_next(request)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 156, in call_next\n    raise app_exc\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 141, in coro\n    await self.app(scope, receive_or_disconnect, send_no_error)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 714, in __call__\n    await self.middleware_stack(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 734, in app\n    await route.handle(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 288, in handle\n    await self.app(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 76, in app\n    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 73, in app\n    response = await f(request)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/fastapi/routing.py\", line 301, in app\n    raw_response = await run_endpoint_function(\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/fastapi/routing.py\", line 212, in run_endpoint_function\n    return await dependant.call(**values)\n  File \"/Users/simba/Downloads/Personal AI Agent/main.py\", line 424, in list_todos\n    return todo_service.list_tasks(current_user.username)\nTypeError: list_tasks() takes 1 positional argument but 2 were given"}
{"timestamp": "2025-04-22T21:02:13.602996", "level": "ERROR", "message": "Error in api", "module": "logger", "function": "log_error", "line": 108, "exception": "  + Exception Group Traceback (most recent call last):\n  |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_utils.py\", line 76, in collapse_excgroups\n  |     yield\n  |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 181, in __call__\n  |     recv_stream.close()\n  |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 772, in __aexit__\n  |     raise BaseExceptionGroup(\n  | exceptiongroup.ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\n  +-+---------------- 1 ----------------\n    | Traceback (most recent call last):\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/errors.py\", line 165, in __call__\n    |     await self.app(scope, receive, _send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/cors.py\", line 93, in __call__\n    |     await self.simple_response(scope, receive, send, request_headers=headers)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/cors.py\", line 144, in simple_response\n    |     await self.app(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 29, in __call__\n    |     await responder(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 126, in __call__\n    |     await super().__call__(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 46, in __call__\n    |     await self.app(scope, receive, self.send_with_compression)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 181, in __call__\n    |     recv_stream.close()\n    |   File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/contextlib.py\", line 135, in __exit__\n    |     self.gen.throw(type, value, traceback)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_utils.py\", line 82, in collapse_excgroups\n    |     raise exc\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 178, in __call__\n    |     response = await self.dispatch_func(request, call_next)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/main.py\", line 145, in __call__\n    |     response = await call_next(request)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 156, in call_next\n    |     raise app_exc\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 141, in coro\n    |     await self.app(scope, receive_or_disconnect, send_no_error)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n    |     await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    |     raise exc\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    |     await app(scope, receive, sender)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 714, in __call__\n    |     await self.middleware_stack(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 734, in app\n    |     await route.handle(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 288, in handle\n    |     await self.app(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 76, in app\n    |     await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    |     raise exc\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    |     await app(scope, receive, sender)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 73, in app\n    |     response = await f(request)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/fastapi/routing.py\", line 301, in app\n    |     raw_response = await run_endpoint_function(\n    |   File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/fastapi/routing.py\", line 212, in run_endpoint_function\n    |     return await dependant.call(**values)\n    |   File \"/Users/simba/Downloads/Personal AI Agent/main.py\", line 424, in list_todos\n    |     return todo_service.list_tasks(current_user.username)\n    | TypeError: list_tasks() takes 1 positional argument but 2 were given\n    +------------------------------------\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/errors.py\", line 165, in __call__\n    await self.app(scope, receive, _send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/cors.py\", line 93, in __call__\n    await self.simple_response(scope, receive, send, request_headers=headers)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/cors.py\", line 144, in simple_response\n    await self.app(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 29, in __call__\n    await responder(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 126, in __call__\n    await super().__call__(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/gzip.py\", line 46, in __call__\n    await self.app(scope, receive, self.send_with_compression)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 181, in __call__\n    recv_stream.close()\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/contextlib.py\", line 135, in __exit__\n    self.gen.throw(type, value, traceback)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_utils.py\", line 82, in collapse_excgroups\n    raise exc\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 178, in __call__\n    response = await self.dispatch_func(request, call_next)\n  File \"/Users/simba/Downloads/Personal AI Agent/main.py\", line 145, in __call__\n    response = await call_next(request)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 156, in call_next\n    raise app_exc\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/base.py\", line 141, in coro\n    await self.app(scope, receive_or_disconnect, send_no_error)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 714, in __call__\n    await self.middleware_stack(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 734, in app\n    await route.handle(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 288, in handle\n    await self.app(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 76, in app\n    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/starlette/routing.py\", line 73, in app\n    response = await f(request)\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/fastapi/routing.py\", line 301, in app\n    raw_response = await run_endpoint_function(\n  File \"/Users/simba/Downloads/Personal AI Agent/.venv/lib/python3.9/site-packages/fastapi/routing.py\", line 212, in run_endpoint_function\n    return await dependant.call(**values)\n  File \"/Users/simba/Downloads/Personal AI Agent/main.py\", line 424, in list_todos\n    return todo_service.list_tasks(current_user.username)\nTypeError: list_tasks() takes 1 positional argument but 2 were given"}
{"timestamp": "2025-04-22T21:04:17.385228", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-22T21:04:29.763388", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-22T21:04:29.764601", "level": "INFO", "message": "Request: POST /assist - Time: 12.3804s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T21:04:29.828122", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 228}
{"timestamp": "2025-04-22T21:04:29.829027", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 230}
{"timestamp": "2025-04-22T21:04:30.662511", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 222}
{"timestamp": "2025-04-22T21:04:30.667589", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-22T21:04:42.081228", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-22T21:04:42.081499", "level": "INFO", "message": "Request: POST /assist - Time: 11.4165s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T21:05:04.421709", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 228}
{"timestamp": "2025-04-22T21:05:04.422210", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 230}
{"timestamp": "2025-04-22T21:05:05.076232", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 222}
{"timestamp": "2025-04-22T21:05:24.281728", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 228}
{"timestamp": "2025-04-22T21:05:24.283848", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 230}
{"timestamp": "2025-04-22T21:05:24.949678", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 222}
{"timestamp": "2025-04-22T21:06:13.658638", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-22T21:06:24.139096", "level": "INFO", "message": "Request: GET /todos - Time: 0.0024s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T21:06:24.143983", "level": "INFO", "message": "Request: GET /todos - Time: 0.0010s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T21:06:24.195230", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-22T21:06:24.195545", "level": "INFO", "message": "Request: POST /assist - Time: 10.5421s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T21:06:35.765007", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-22T21:06:48.476444", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-22T21:06:48.476947", "level": "INFO", "message": "Request: POST /assist - Time: 12.7144s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T21:07:17.237651", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 228}
{"timestamp": "2025-04-22T21:07:17.237864", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 230}
{"timestamp": "2025-04-22T21:07:23.644792", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 222}
{"timestamp": "2025-04-22T21:07:47.370972", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-22T21:07:58.934481", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-22T21:07:58.935262", "level": "INFO", "message": "Request: POST /assist - Time: 11.5719s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T21:10:07.174997", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 228}
{"timestamp": "2025-04-22T21:10:07.175231", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 230}
{"timestamp": "2025-04-22T21:10:07.911187", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 222}
{"timestamp": "2025-04-22T21:10:28.457970", "level": "INFO", "message": "Request: GET /llm-test - Time: 15.9131s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T21:10:40.606681", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-22T21:10:56.080066", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-22T21:10:56.080813", "level": "INFO", "message": "Request: POST /assist - Time: 15.4829s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T21:11:33.056866", "level": "INFO", "message": "Request: GET /llm-test - Time: 11.2713s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T21:12:07.942295", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 228}
{"timestamp": "2025-04-22T21:12:07.942650", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 230}
{"timestamp": "2025-04-22T21:12:08.594787", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 222}
{"timestamp": "2025-04-22T21:12:15.061673", "level": "INFO", "message": "Request: GET /llm-test - Time: 1.7957s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T21:13:27.070482", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 228}
{"timestamp": "2025-04-22T21:13:27.070664", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 230}
{"timestamp": "2025-04-22T21:13:29.717459", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 222}
{"timestamp": "2025-04-22T21:13:35.985332", "level": "INFO", "message": "Request: GET /llm-test - Time: 1.6406s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T21:13:44.359372", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-22T21:13:46.064618", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-22T21:13:46.064855", "level": "INFO", "message": "Request: POST /assist - Time: 1.7088s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T21:13:48.334041", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-22T21:13:49.802975", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-22T21:13:49.803195", "level": "INFO", "message": "Request: POST /assist - Time: 1.4701s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T21:15:43.356665", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 228}
{"timestamp": "2025-04-22T21:15:43.357968", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 230}
{"timestamp": "2025-04-22T21:15:44.154097", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 222}
{"timestamp": "2025-04-22T21:19:47.849465", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 228}
{"timestamp": "2025-04-22T21:19:47.888184", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 230}
{"timestamp": "2025-04-22T21:21:13.975070", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 222}
{"timestamp": "2025-04-22T21:21:25.197288", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 228}
{"timestamp": "2025-04-22T21:21:25.200085", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 230}
{"timestamp": "2025-04-22T21:43:05.888436", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 222}
{"timestamp": "2025-04-22T21:43:20.253521", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 228}
{"timestamp": "2025-04-22T21:43:20.255860", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 230}
{"timestamp": "2025-04-22T21:43:24.495075", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 222}
{"timestamp": "2025-04-22T21:44:40.440903", "level": "INFO", "message": "Successful login for user: testuser", "module": "main", "function": "login_for_access_token", "line": 288}
{"timestamp": "2025-04-22T21:44:40.444913", "level": "INFO", "message": "Request: POST /token - Time: 0.2560s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T21:44:50.148633", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-22T21:44:50.539513", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-22T21:44:50.540086", "level": "INFO", "message": "Request: POST /assist - Time: 0.3933s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T21:45:48.007513", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 228}
{"timestamp": "2025-04-22T21:45:48.007739", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 230}
{"timestamp": "2025-04-22T21:45:48.648095", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 222}
{"timestamp": "2025-04-22T21:46:12.090672", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-22T21:46:12.352958", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-22T21:46:12.353387", "level": "INFO", "message": "Request: POST /assist - Time: 0.2700s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T21:46:13.564261", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-22T21:46:13.689881", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-22T21:46:13.690266", "level": "INFO", "message": "Request: POST /assist - Time: 0.1282s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T21:46:14.371880", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-22T21:46:14.492206", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-22T21:46:14.492588", "level": "INFO", "message": "Request: POST /assist - Time: 0.1226s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T21:46:47.713000", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 228}
{"timestamp": "2025-04-22T21:46:47.713260", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 230}
{"timestamp": "2025-04-22T21:46:48.370090", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 222}
{"timestamp": "2025-04-22T21:47:14.275759", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-22T21:47:15.110740", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-22T21:47:15.111329", "level": "INFO", "message": "Request: POST /assist - Time: 0.8422s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T21:47:26.608844", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-22T21:47:27.297569", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-22T21:47:27.298313", "level": "INFO", "message": "Request: POST /assist - Time: 0.6922s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T21:47:37.394885", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-22T21:47:39.279652", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-22T21:47:39.280666", "level": "INFO", "message": "Request: POST /assist - Time: 1.8873s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T21:47:45.771557", "level": "INFO", "message": "Request: GET /todos - Time: 0.0013s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T21:47:45.774750", "level": "INFO", "message": "Request: GET /todos - Time: 0.0010s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T21:47:54.376165", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-22T21:47:54.381908", "level": "ERROR", "message": "Error in todo", "module": "logger", "function": "log_error", "line": 108, "exception": "Traceback (most recent call last):\n  File \"/Users/simba/Downloads/Personal AI Agent/main.py\", line 366, in process_request\n    response = await todo_service.process(message.content, message.parameters)\n  File \"/Users/simba/Downloads/Personal AI Agent/services/todo_manager.py\", line 78, in process\n    command = content.lower().strip()\nAttributeError: 'dict' object has no attribute 'lower'"}
{"timestamp": "2025-04-22T21:47:54.382708", "level": "INFO", "message": "Request: POST /assist - Time: 0.0095s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T21:47:56.109382", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-22T21:47:56.111111", "level": "ERROR", "message": "Error in todo", "module": "logger", "function": "log_error", "line": 108, "exception": "Traceback (most recent call last):\n  File \"/Users/simba/Downloads/Personal AI Agent/main.py\", line 366, in process_request\n    response = await todo_service.process(message.content, message.parameters)\n  File \"/Users/simba/Downloads/Personal AI Agent/services/todo_manager.py\", line 78, in process\n    command = content.lower().strip()\nAttributeError: 'dict' object has no attribute 'lower'"}
{"timestamp": "2025-04-22T21:47:56.111799", "level": "INFO", "message": "Request: POST /assist - Time: 0.0050s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T21:47:57.428460", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-22T21:47:57.429699", "level": "ERROR", "message": "Error in todo", "module": "logger", "function": "log_error", "line": 108, "exception": "Traceback (most recent call last):\n  File \"/Users/simba/Downloads/Personal AI Agent/main.py\", line 366, in process_request\n    response = await todo_service.process(message.content, message.parameters)\n  File \"/Users/simba/Downloads/Personal AI Agent/services/todo_manager.py\", line 78, in process\n    command = content.lower().strip()\nAttributeError: 'dict' object has no attribute 'lower'"}
{"timestamp": "2025-04-22T21:47:57.430571", "level": "INFO", "message": "Request: POST /assist - Time: 0.0054s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T21:48:03.611594", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-22T21:48:09.933793", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-22T21:48:09.934716", "level": "INFO", "message": "Request: POST /assist - Time: 6.3246s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T21:48:23.033864", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-22T21:48:23.567280", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-22T21:48:23.568037", "level": "INFO", "message": "Request: POST /assist - Time: 0.5369s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T21:48:35.407254", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-22T21:48:36.067190", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-22T21:48:36.067833", "level": "INFO", "message": "Request: POST /assist - Time: 0.6622s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T21:48:52.866300", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-22T21:48:53.880077", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-22T21:48:53.880676", "level": "INFO", "message": "Request: POST /assist - Time: 1.0171s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T21:49:08.643279", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-22T21:49:09.338052", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-22T21:49:09.338573", "level": "INFO", "message": "Request: POST /assist - Time: 0.6981s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T21:49:15.774655", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-22T21:49:17.228036", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-22T21:49:17.228714", "level": "INFO", "message": "Request: POST /assist - Time: 1.4554s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T21:49:31.037387", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-22T21:49:31.763249", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-22T21:49:31.763714", "level": "INFO", "message": "Request: POST /assist - Time: 0.7299s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T21:50:00.280092", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 228}
{"timestamp": "2025-04-22T21:50:00.280528", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 230}
{"timestamp": "2025-04-22T21:52:48.152220", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 222}
{"timestamp": "2025-04-22T21:52:59.984030", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 228}
{"timestamp": "2025-04-22T21:52:59.986087", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 230}
{"timestamp": "2025-04-22T21:53:02.899942", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 222}
{"timestamp": "2025-04-22T21:54:18.655985", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-22T21:54:19.426499", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-22T21:54:19.427033", "level": "INFO", "message": "Request: POST /assist - Time: 0.7747s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T21:54:28.066607", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-22T21:54:28.066861", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-22T21:54:28.068005", "level": "INFO", "message": "Request: POST /assist - Time: 0.0040s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T21:54:33.690086", "level": "INFO", "message": "Request: GET /todos - Time: 0.0025s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T21:54:33.694771", "level": "INFO", "message": "Request: GET /todos - Time: 0.0010s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T21:54:40.036399", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-22T21:54:43.583961", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-22T21:54:43.584691", "level": "INFO", "message": "Request: POST /assist - Time: 3.5503s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T21:54:52.451699", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-22T21:54:53.001562", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-22T21:54:53.002163", "level": "INFO", "message": "Request: POST /assist - Time: 0.5527s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T21:55:00.901339", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-22T21:55:01.807715", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-22T21:55:01.808404", "level": "INFO", "message": "Request: POST /assist - Time: 0.9099s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T21:55:15.278677", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-22T21:55:15.938692", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-22T21:55:15.939273", "level": "INFO", "message": "Request: POST /assist - Time: 0.6634s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T21:55:36.787280", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-22T21:55:37.439377", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-22T21:55:37.439947", "level": "INFO", "message": "Request: POST /assist - Time: 0.6547s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T21:55:43.618872", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-22T21:55:44.198873", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-22T21:55:44.199430", "level": "INFO", "message": "Request: POST /assist - Time: 0.5826s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T21:55:48.506594", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-22T21:55:48.909615", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-22T21:55:48.910268", "level": "INFO", "message": "Request: POST /assist - Time: 0.4060s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T21:55:52.998176", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-22T21:55:53.311569", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-22T21:55:53.312124", "level": "INFO", "message": "Request: POST /assist - Time: 0.3156s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T21:55:56.680009", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-22T21:55:57.101907", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-22T21:55:57.102392", "level": "INFO", "message": "Request: POST /assist - Time: 0.4251s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T21:56:11.735567", "level": "INFO", "message": "Request: GET /todos - Time: 0.0022s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T21:56:11.740738", "level": "INFO", "message": "Request: GET /todos - Time: 0.0015s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T21:59:37.456958", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-22T21:59:37.457054", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-22T21:59:37.457360", "level": "INFO", "message": "Request: POST /assist - Time: 0.0011s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T21:59:50.141585", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-22T21:59:51.422218", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-22T21:59:51.422807", "level": "INFO", "message": "Request: POST /assist - Time: 1.2829s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T22:03:39.697179", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-22T22:03:39.697571", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-22T22:03:39.698331", "level": "INFO", "message": "Request: POST /assist - Time: 0.0035s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T22:03:42.816129", "level": "INFO", "message": "Request: GET /todos - Time: 0.0017s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T22:03:42.820301", "level": "INFO", "message": "Request: GET /todos - Time: 0.0010s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T22:03:52.209932", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-22T22:03:52.759019", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-22T22:03:52.759673", "level": "INFO", "message": "Request: POST /assist - Time: 0.5513s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T22:03:56.085218", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-22T22:03:56.443221", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-22T22:03:56.443742", "level": "INFO", "message": "Request: POST /assist - Time: 0.3609s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T22:03:58.919279", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-22T22:03:59.306887", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-22T22:03:59.307365", "level": "INFO", "message": "Request: POST /assist - Time: 0.3900s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T22:04:02.550289", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-22T22:04:03.403249", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-22T22:04:03.403646", "level": "INFO", "message": "Request: POST /assist - Time: 0.8562s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T22:07:08.450098", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-22T22:07:08.450819", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-22T22:07:08.451402", "level": "INFO", "message": "Request: POST /assist - Time: 0.0029s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T22:07:18.554009", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-22T22:07:19.102772", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-22T22:07:19.103512", "level": "INFO", "message": "Request: POST /assist - Time: 0.5514s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T22:15:23.283079", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 228}
{"timestamp": "2025-04-22T22:15:23.283432", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 230}
{"timestamp": "2025-04-22T22:15:24.104301", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 222}
{"timestamp": "2025-04-22T22:17:08.403933", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 228}
{"timestamp": "2025-04-22T22:17:08.407586", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 230}
{"timestamp": "2025-04-22T22:17:09.060380", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 222}
{"timestamp": "2025-04-22T22:20:01.163248", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 228}
{"timestamp": "2025-04-22T22:20:01.165627", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 230}
{"timestamp": "2025-04-22T22:20:01.843365", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 222}
{"timestamp": "2025-04-22T22:23:24.671047", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 228}
{"timestamp": "2025-04-22T22:23:24.673276", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 230}
{"timestamp": "2025-04-22T22:23:25.389425", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 222}
{"timestamp": "2025-04-22T22:25:33.753618", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 228}
{"timestamp": "2025-04-22T22:25:33.757173", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 230}
{"timestamp": "2025-04-22T22:25:34.432354", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 222}
{"timestamp": "2025-04-22T22:26:40.470974", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 228}
{"timestamp": "2025-04-22T22:26:40.473658", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 230}
{"timestamp": "2025-04-22T22:26:41.132431", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 222}
{"timestamp": "2025-04-22T22:29:37.355956", "level": "INFO", "message": "Request: POST /assist - Time: 0.0065s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T22:29:38.460665", "level": "INFO", "message": "Request: POST /assist - Time: 0.0007s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T22:29:43.677353", "level": "INFO", "message": "Request: GET /todos - Time: 0.0020s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T22:29:43.680858", "level": "INFO", "message": "Request: GET /todos - Time: 0.0010s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T22:29:49.484923", "level": "INFO", "message": "Request: GET /todos - Time: 0.0018s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-22T22:29:49.488250", "level": "INFO", "message": "Request: GET /todos - Time: 0.0008s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T15:41:36.670918", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 222}
{"timestamp": "2025-04-23T15:41:49.426865", "level": "INFO", "message": "Request: POST /assist - Time: 0.0069s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T15:41:50.372007", "level": "INFO", "message": "Request: POST /assist - Time: 0.0017s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T15:48:24.091650", "level": "INFO", "message": "Starting LLM Assistant API on 0.0.0.0:8000", "module": "main", "function": "<module>", "line": 528}
{"timestamp": "2025-04-23T15:48:24.762408", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 222}
{"timestamp": "2025-04-23T15:49:32.676973", "level": "INFO", "message": "Request: POST /assist - Time: 0.0025s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T15:50:01.545186", "level": "INFO", "message": "Request: POST /assist - Time: 0.0041s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T15:51:11.194722", "level": "INFO", "message": "Request: POST /assist - Time: 0.0012s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T15:52:59.642366", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 222}
{"timestamp": "2025-04-23T15:53:30.300330", "level": "INFO", "message": "Request: POST /assist - Time: 0.0031s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T15:55:18.255168", "level": "INFO", "message": "Request: POST /assist - Time: 0.0013s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T15:55:27.984756", "level": "WARNING", "message": "Failed login attempt for user: testuser", "module": "main", "function": "login_for_access_token", "line": 281}
{"timestamp": "2025-04-23T15:55:27.985202", "level": "INFO", "message": "Request: POST /token - Time: 0.2520s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T15:55:38.286294", "level": "WARNING", "message": "Failed login attempt for user: testuser", "module": "main", "function": "login_for_access_token", "line": 281}
{"timestamp": "2025-04-23T15:55:38.286713", "level": "INFO", "message": "Request: POST /token - Time: 0.2459s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T15:55:39.655975", "level": "WARNING", "message": "Failed login attempt for user: testuser", "module": "main", "function": "login_for_access_token", "line": 281}
{"timestamp": "2025-04-23T15:55:39.656262", "level": "INFO", "message": "Request: POST /token - Time: 0.2385s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T15:56:18.906392", "level": "INFO", "message": "Successful login for user: testuser", "module": "main", "function": "login_for_access_token", "line": 288}
{"timestamp": "2025-04-23T15:56:18.907181", "level": "INFO", "message": "Request: POST /token - Time: 0.2519s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T15:56:23.181377", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T15:56:23.858399", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-23T15:56:23.859101", "level": "INFO", "message": "Request: POST /assist - Time: 0.6819s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T15:56:31.954406", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T15:56:33.284490", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-23T15:56:33.285526", "level": "INFO", "message": "Request: POST /assist - Time: 1.3330s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T15:56:42.364685", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T15:56:44.441470", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-23T15:56:44.442494", "level": "INFO", "message": "Request: POST /assist - Time: 2.0801s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T15:56:50.974044", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T15:56:52.940116", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-23T15:56:52.941119", "level": "INFO", "message": "Request: POST /assist - Time: 1.9695s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T15:56:58.752611", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T15:57:00.523245", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-23T15:57:00.523888", "level": "INFO", "message": "Request: POST /assist - Time: 1.7731s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T15:57:05.053037", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T15:57:05.940990", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-23T15:57:05.941559", "level": "INFO", "message": "Request: POST /assist - Time: 0.8911s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T15:57:22.414915", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T15:57:23.656386", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-23T15:57:23.656975", "level": "INFO", "message": "Request: POST /assist - Time: 1.2448s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T15:57:59.511328", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T15:58:03.602255", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-23T15:58:03.602824", "level": "INFO", "message": "Request: POST /assist - Time: 4.0928s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T19:58:13.078182", "level": "INFO", "message": "Starting LLM Assistant API on 0.0.0.0:8000", "module": "main", "function": "<module>", "line": 528}
{"timestamp": "2025-04-23T19:58:13.658114", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 222}
{"timestamp": "2025-04-23T19:58:43.316081", "level": "INFO", "message": "Successful login for user: testuser", "module": "main", "function": "login_for_access_token", "line": 288}
{"timestamp": "2025-04-23T19:58:43.316663", "level": "INFO", "message": "Request: POST /token - Time: 0.2407s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T19:58:47.835792", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T19:58:48.528787", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-23T19:58:48.529060", "level": "INFO", "message": "Request: POST /assist - Time: 0.6949s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T19:58:57.725332", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T19:58:58.944463", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-23T19:58:58.945018", "level": "INFO", "message": "Request: POST /assist - Time: 1.2203s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T19:59:29.987408", "level": "INFO", "message": "Successful login for user: testuser", "module": "main", "function": "login_for_access_token", "line": 288}
{"timestamp": "2025-04-23T19:59:29.987776", "level": "INFO", "message": "Request: POST /token - Time: 0.2579s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T20:05:16.571981", "level": "INFO", "message": "Request: GET /todos - Time: 0.0006s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T20:05:16.574317", "level": "INFO", "message": "Request: GET /todos - Time: 0.0009s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T20:05:29.725134", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T20:05:29.725853", "level": "ERROR", "message": "Error during LLMClient summarization: name 'model' is not defined", "module": "summarize", "function": "process", "line": 105, "exception": "Traceback (most recent call last):\n  File \"/Users/simba/Downloads/Personal-AI-Agent/services/summarize.py\", line 83, in process\n    model=model\n          ^^^^^\nNameError: name 'model' is not defined"}
{"timestamp": "2025-04-23T20:05:29.726095", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-23T20:05:29.726345", "level": "INFO", "message": "Request: POST /assist - Time: 0.0019s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T20:07:59.462277", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T20:08:00.121408", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-23T20:08:00.121677", "level": "INFO", "message": "Request: POST /assist - Time: 0.6600s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T20:08:04.701392", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T20:08:05.375700", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-23T20:08:05.376185", "level": "INFO", "message": "Request: POST /assist - Time: 0.6761s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T20:09:46.971474", "level": "INFO", "message": "Request: GET /todos - Time: 0.0005s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T20:09:46.974283", "level": "INFO", "message": "Request: GET /todos - Time: 0.0005s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T20:09:51.047351", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T20:09:51.659096", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-23T20:09:51.659362", "level": "INFO", "message": "Request: POST /assist - Time: 0.6135s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T20:09:56.626654", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T20:09:57.159500", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-23T20:09:57.159720", "level": "INFO", "message": "Request: POST /assist - Time: 0.5340s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T20:10:18.471151", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T20:10:18.981242", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-23T20:10:18.981443", "level": "INFO", "message": "Request: POST /assist - Time: 0.5115s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T20:10:33.302189", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T20:10:34.510678", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-23T20:10:34.511104", "level": "INFO", "message": "Request: POST /assist - Time: 1.2095s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T20:10:42.797516", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T20:10:47.043839", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-23T20:10:47.044313", "level": "INFO", "message": "Request: POST /assist - Time: 4.2485s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T20:11:00.287719", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T20:11:02.048479", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-23T20:11:02.048851", "level": "INFO", "message": "Request: POST /assist - Time: 1.7639s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T20:11:10.639714", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T20:11:14.567102", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-23T20:11:14.567418", "level": "INFO", "message": "Request: POST /assist - Time: 3.9295s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T20:11:31.498318", "level": "INFO", "message": "Request: GET /todos - Time: 0.0009s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T20:11:31.500879", "level": "INFO", "message": "Request: GET /todos - Time: 0.0005s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T20:11:50.553517", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T20:11:52.871257", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-23T20:11:52.873201", "level": "INFO", "message": "Request: POST /assist - Time: 2.3204s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T20:12:11.928349", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T20:12:17.563551", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-23T20:12:17.564089", "level": "INFO", "message": "Request: POST /assist - Time: 5.6365s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T20:16:36.129168", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T20:16:36.928380", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-23T20:16:36.928710", "level": "INFO", "message": "Request: POST /assist - Time: 0.8001s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T20:17:41.908603", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T20:17:42.462940", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-23T20:17:42.463169", "level": "INFO", "message": "Request: POST /assist - Time: 0.5555s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T20:17:49.966064", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T20:17:50.552873", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-23T20:17:50.553103", "level": "INFO", "message": "Request: POST /assist - Time: 0.5878s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T20:18:36.784577", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T20:18:37.279245", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-23T20:18:37.279540", "level": "INFO", "message": "Request: POST /assist - Time: 0.4955s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T20:24:09.723409", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 228}
{"timestamp": "2025-04-23T20:24:09.724608", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 230}
{"timestamp": "2025-04-23T20:24:10.407466", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 222}
{"timestamp": "2025-04-23T20:24:50.832289", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 228}
{"timestamp": "2025-04-23T20:24:50.836944", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 230}
{"timestamp": "2025-04-23T20:24:51.538410", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 222}
{"timestamp": "2025-04-23T20:25:10.229306", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T20:25:10.943231", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-23T20:25:10.943626", "level": "INFO", "message": "Request: POST /assist - Time: 0.7161s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T20:25:25.283828", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T20:25:27.218582", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-23T20:25:27.218965", "level": "INFO", "message": "Request: POST /assist - Time: 1.9360s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T20:25:40.082660", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T20:25:40.591624", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-23T20:25:40.591857", "level": "INFO", "message": "Request: POST /assist - Time: 0.5100s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T20:25:44.277339", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 228}
{"timestamp": "2025-04-23T20:25:44.277596", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 230}
{"timestamp": "2025-04-23T20:25:44.968317", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 222}
{"timestamp": "2025-04-23T20:28:45.984242", "level": "INFO", "message": "Starting LLM Assistant API on 0.0.0.0:8000", "module": "main", "function": "<module>", "line": 528}
{"timestamp": "2025-04-23T20:29:00.702225", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T20:29:00.702832", "level": "ERROR", "message": "Error in chat", "module": "logger", "function": "log_error", "line": 108, "exception": "Traceback (most recent call last):\n  File \"/Users/simba/Downloads/Personal-AI-Agent/main.py\", line 372, in process_request\n    response = await chat_service.process(message.content, message.parameters)\n                     ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nTypeError: ChatService.process() takes 2 positional arguments but 3 were given"}
{"timestamp": "2025-04-23T20:29:00.703163", "level": "INFO", "message": "Request: POST /assist - Time: 0.0022s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T20:29:03.247948", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T20:29:03.248491", "level": "ERROR", "message": "Error in chat", "module": "logger", "function": "log_error", "line": 108, "exception": "Traceback (most recent call last):\n  File \"/Users/simba/Downloads/Personal-AI-Agent/main.py\", line 372, in process_request\n    response = await chat_service.process(message.content, message.parameters)\n                     ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nTypeError: ChatService.process() takes 2 positional arguments but 3 were given"}
{"timestamp": "2025-04-23T20:29:03.248946", "level": "INFO", "message": "Request: POST /assist - Time: 0.0020s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T20:31:37.489654", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 228}
{"timestamp": "2025-04-23T20:31:37.489830", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 230}
{"timestamp": "2025-04-23T20:31:38.095077", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 222}
{"timestamp": "2025-04-23T20:31:57.901226", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 228}
{"timestamp": "2025-04-23T20:31:57.904337", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 230}
{"timestamp": "2025-04-23T20:31:58.491372", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 222}
{"timestamp": "2025-04-23T20:32:00.727132", "level": "INFO", "message": "Request: POST /assist - Time: 0.0008s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T20:32:01.899705", "level": "INFO", "message": "Request: POST /assist - Time: 0.0007s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T20:32:02.651691", "level": "INFO", "message": "Request: POST /assist - Time: 0.0011s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T20:33:46.220346", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 228}
{"timestamp": "2025-04-23T20:33:46.220525", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 230}
{"timestamp": "2025-04-23T20:33:46.788142", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 222}
{"timestamp": "2025-04-23T20:33:54.469395", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 228}
{"timestamp": "2025-04-23T20:33:54.475303", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 230}
{"timestamp": "2025-04-23T20:33:55.049698", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 222}
{"timestamp": "2025-04-23T20:33:58.276253", "level": "INFO", "message": "Request: POST /assist - Time: 0.0018s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T20:33:58.867958", "level": "INFO", "message": "Request: POST /assist - Time: 0.0014s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T20:33:59.269670", "level": "INFO", "message": "Request: POST /assist - Time: 0.0021s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T20:34:06.425493", "level": "INFO", "message": "Request: POST /assist - Time: 0.0016s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T20:34:07.333396", "level": "INFO", "message": "Request: POST /assist - Time: 0.0010s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T20:37:31.269572", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 228}
{"timestamp": "2025-04-23T20:37:31.269738", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 230}
{"timestamp": "2025-04-23T20:37:31.951062", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 222}
{"timestamp": "2025-04-23T20:37:34.172720", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 228}
{"timestamp": "2025-04-23T20:37:34.177310", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 230}
{"timestamp": "2025-04-23T20:37:34.762521", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 218}
{"timestamp": "2025-04-23T20:38:04.779647", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 224}
{"timestamp": "2025-04-23T20:38:04.784654", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 226}
{"timestamp": "2025-04-23T20:38:05.372371", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 218}
{"timestamp": "2025-04-23T20:38:48.859597", "level": "INFO", "message": "Request: POST /assist - Time: 0.0009s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T20:38:49.423975", "level": "INFO", "message": "Request: POST /assist - Time: 0.0012s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T20:38:49.856823", "level": "INFO", "message": "Request: POST /assist - Time: 0.0006s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T20:38:55.447159", "level": "INFO", "message": "Request: POST /assist - Time: 0.0005s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T20:39:42.034959", "level": "INFO", "message": "Successful login for user: testuser", "module": "main", "function": "login_for_access_token", "line": 284}
{"timestamp": "2025-04-23T20:39:42.035363", "level": "INFO", "message": "Request: POST /token - Time: 0.2360s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T20:40:57.840641", "level": "INFO", "message": "Request: POST /assist - Time: 0.0008s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T20:40:59.051027", "level": "INFO", "message": "Request: POST /assist - Time: 0.0013s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T20:43:15.767404", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 224}
{"timestamp": "2025-04-23T20:43:15.767776", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 226}
{"timestamp": "2025-04-23T20:43:18.165810", "level": "INFO", "message": "Starting LLM Assistant API on 0.0.0.0:8000", "module": "main", "function": "<module>", "line": 524}
{"timestamp": "2025-04-23T20:43:18.736576", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 218}
{"timestamp": "2025-04-23T20:43:33.335597", "level": "INFO", "message": "Request: POST /assist - Time: 0.0009s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T20:43:50.497039", "level": "INFO", "message": "Successful login for user: testuser", "module": "main", "function": "login_for_access_token", "line": 284}
{"timestamp": "2025-04-23T20:43:50.497407", "level": "INFO", "message": "Request: POST /token - Time: 0.2389s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T20:43:56.447999", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T20:43:56.626530", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-23T20:43:56.626753", "level": "INFO", "message": "Request: POST /assist - Time: 0.1814s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T20:43:59.947054", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T20:44:00.089354", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-23T20:44:00.089680", "level": "INFO", "message": "Request: POST /assist - Time: 0.1433s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T20:44:07.471264", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T20:44:07.641000", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-23T20:44:07.641318", "level": "INFO", "message": "Request: POST /assist - Time: 0.1714s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T20:44:12.205946", "level": "INFO", "message": "Request: GET /todos - Time: 0.0012s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T20:44:12.209599", "level": "INFO", "message": "Request: GET /todos - Time: 0.0008s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T20:44:18.179314", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T20:44:18.180336", "level": "ERROR", "message": "Error in chat", "module": "logger", "function": "log_error", "line": 108, "exception": "Traceback (most recent call last):\n  File \"/Users/simba/Downloads/Personal-AI-Agent/main.py\", line 368, in process_request\n    response = await chat_service.process(message.content, message.parameters)\n                     ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nTypeError: ChatService.process() takes 2 positional arguments but 3 were given"}
{"timestamp": "2025-04-23T20:44:18.180927", "level": "INFO", "message": "Request: POST /assist - Time: 0.0024s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T20:48:57.047582", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 224}
{"timestamp": "2025-04-23T20:48:57.050048", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 226}
{"timestamp": "2025-04-23T20:52:26.742042", "level": "INFO", "message": "Starting LLM Assistant API on 0.0.0.0:8000", "module": "main", "function": "<module>", "line": 524}
{"timestamp": "2025-04-23T20:52:27.318370", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 218}
{"timestamp": "2025-04-23T20:52:30.619744", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T20:52:30.855753", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-23T20:52:30.856252", "level": "INFO", "message": "Request: POST /assist - Time: 0.2381s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T20:52:31.550131", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T20:52:31.617846", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-23T20:52:31.618292", "level": "INFO", "message": "Request: POST /assist - Time: 0.0695s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T20:52:32.164329", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T20:52:32.245813", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-23T20:52:32.246133", "level": "INFO", "message": "Request: POST /assist - Time: 0.0825s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T20:53:33.111094", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T20:53:33.268066", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-23T20:53:33.268424", "level": "INFO", "message": "Request: POST /assist - Time: 0.1583s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T20:54:47.130399", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 224}
{"timestamp": "2025-04-23T20:54:47.131566", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 226}
{"timestamp": "2025-04-23T20:54:47.816361", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 218}
{"timestamp": "2025-04-23T20:55:55.917459", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 224}
{"timestamp": "2025-04-23T20:55:55.921788", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 226}
{"timestamp": "2025-04-23T20:57:37.015074", "level": "INFO", "message": "Starting LLM Assistant API on 0.0.0.0:8000", "module": "main", "function": "<module>", "line": 524}
{"timestamp": "2025-04-23T20:57:37.591212", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 218}
{"timestamp": "2025-04-23T20:57:48.398932", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T20:57:48.399104", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-23T20:57:48.399421", "level": "INFO", "message": "Request: POST /assist - Time: 0.0020s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T20:58:07.305578", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 224}
{"timestamp": "2025-04-23T20:58:07.305755", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 226}
{"timestamp": "2025-04-23T20:58:07.996464", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 218}
{"timestamp": "2025-04-23T21:00:06.645654", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 224}
{"timestamp": "2025-04-23T21:00:06.650434", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 226}
{"timestamp": "2025-04-23T21:00:07.322818", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 218}
{"timestamp": "2025-04-23T21:00:13.498063", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 224}
{"timestamp": "2025-04-23T21:00:13.500728", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 226}
{"timestamp": "2025-04-23T21:00:14.094114", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 218}
{"timestamp": "2025-04-23T21:01:36.203358", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 224}
{"timestamp": "2025-04-23T21:01:36.207063", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 226}
{"timestamp": "2025-04-23T21:01:39.483374", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 218}
{"timestamp": "2025-04-23T21:01:55.440646", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T21:01:55.654358", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-23T21:01:55.654785", "level": "INFO", "message": "Request: POST /assist - Time: 0.2155s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T21:02:51.054942", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 224}
{"timestamp": "2025-04-23T21:02:51.055287", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 226}
{"timestamp": "2025-04-23T21:02:51.711812", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 218}
{"timestamp": "2025-04-23T21:03:06.043662", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T21:03:06.211774", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-23T21:03:06.212253", "level": "INFO", "message": "Request: POST /assist - Time: 0.1704s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T21:03:06.783404", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T21:03:06.859970", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-23T21:03:06.860378", "level": "INFO", "message": "Request: POST /assist - Time: 0.0783s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T21:03:07.247777", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T21:03:07.310891", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-23T21:03:07.311116", "level": "INFO", "message": "Request: POST /assist - Time: 0.0649s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T21:03:07.423402", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T21:03:07.492676", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-23T21:03:07.493015", "level": "INFO", "message": "Request: POST /assist - Time: 0.0705s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T21:03:07.643666", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T21:03:07.704495", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-23T21:03:07.704704", "level": "INFO", "message": "Request: POST /assist - Time: 0.0617s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T21:03:13.211210", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T21:03:13.384637", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-23T21:03:13.384904", "level": "INFO", "message": "Request: POST /assist - Time: 0.1749s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T21:03:24.474589", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 224}
{"timestamp": "2025-04-23T21:03:24.476141", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 226}
{"timestamp": "2025-04-23T21:03:27.000872", "level": "INFO", "message": "Starting LLM Assistant API on 0.0.0.0:8000", "module": "main", "function": "<module>", "line": 524}
{"timestamp": "2025-04-23T21:03:27.572781", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 218}
{"timestamp": "2025-04-23T21:03:35.645764", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T21:03:35.795565", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-23T21:03:35.795813", "level": "INFO", "message": "Request: POST /assist - Time: 0.1514s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T21:06:07.327335", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 224}
{"timestamp": "2025-04-23T21:06:07.327763", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 226}
{"timestamp": "2025-04-23T21:06:08.016348", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 218}
{"timestamp": "2025-04-23T21:06:19.749579", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 224}
{"timestamp": "2025-04-23T21:06:19.753927", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 226}
{"timestamp": "2025-04-23T21:06:20.331223", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 218}
{"timestamp": "2025-04-23T21:06:34.951764", "level": "INFO", "message": "Starting LLM Assistant API on 0.0.0.0:8000", "module": "main", "function": "<module>", "line": 524}
{"timestamp": "2025-04-23T21:06:56.550574", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T21:06:59.928244", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-23T21:06:59.929577", "level": "INFO", "message": "Request: POST /assist - Time: 3.3806s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T21:07:08.551949", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T21:07:09.160057", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-23T21:07:09.160717", "level": "INFO", "message": "Request: POST /assist - Time: 0.6097s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T21:07:10.554514", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T21:07:11.145296", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-23T21:07:11.145550", "level": "INFO", "message": "Request: POST /assist - Time: 0.5925s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T21:07:44.759191", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T21:07:44.759314", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-23T21:07:44.759611", "level": "INFO", "message": "Request: POST /assist - Time: 0.0012s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T21:07:54.133094", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T21:07:54.304367", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-23T21:07:54.304566", "level": "INFO", "message": "Request: POST /assist - Time: 0.1723s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T21:08:02.807576", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T21:08:07.677092", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-23T21:08:07.677454", "level": "INFO", "message": "Request: POST /assist - Time: 4.8716s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T21:08:10.200954", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T21:08:15.352939", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-23T21:08:15.353155", "level": "INFO", "message": "Request: POST /assist - Time: 5.1538s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T21:08:19.481618", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T21:08:20.062671", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-23T21:08:20.062939", "level": "INFO", "message": "Request: POST /assist - Time: 0.5835s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T21:08:43.601328", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 224}
{"timestamp": "2025-04-23T21:08:43.601687", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 226}
{"timestamp": "2025-04-23T21:08:44.182660", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 218}
{"timestamp": "2025-04-23T21:08:55.994860", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T21:08:56.630074", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-23T21:08:56.630811", "level": "INFO", "message": "Request: POST /assist - Time: 0.6372s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T21:08:57.431663", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T21:08:57.980510", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-23T21:08:57.981057", "level": "INFO", "message": "Request: POST /assist - Time: 0.5499s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T21:09:33.574567", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T21:09:38.709837", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-23T21:09:38.710075", "level": "INFO", "message": "Request: POST /assist - Time: 5.1364s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T21:10:11.417203", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T21:10:11.418673", "level": "ERROR", "message": "Error in chat", "module": "logger", "function": "log_error", "line": 108, "exception": "Traceback (most recent call last):\n  File \"/Users/simba/Downloads/Personal-AI-Agent/main.py\", line 368, in process_request\n    response = await chat_service.process(message.content, message.parameters)\n                     ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nTypeError: ChatService.process() takes 2 positional arguments but 3 were given"}
{"timestamp": "2025-04-23T21:10:11.419721", "level": "INFO", "message": "Request: POST /assist - Time: 0.0038s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T21:12:26.223782", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 224}
{"timestamp": "2025-04-23T21:12:26.224312", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 226}
{"timestamp": "2025-04-23T21:12:26.917099", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 218}
{"timestamp": "2025-04-23T21:12:54.611404", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 224}
{"timestamp": "2025-04-23T21:12:54.617319", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 226}
{"timestamp": "2025-04-23T21:12:57.225263", "level": "INFO", "message": "Starting LLM Assistant API on 0.0.0.0:8000", "module": "main", "function": "<module>", "line": 524}
{"timestamp": "2025-04-23T21:12:57.798810", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 218}
{"timestamp": "2025-04-23T21:13:09.459257", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T21:13:10.067830", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-23T21:13:10.068153", "level": "INFO", "message": "Request: POST /assist - Time: 0.6108s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T21:14:26.300064", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T21:14:29.710476", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-23T21:14:29.710756", "level": "INFO", "message": "Request: POST /assist - Time: 3.4115s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T21:14:37.964138", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T21:14:37.966072", "level": "ERROR", "message": "Error in chat", "module": "logger", "function": "log_error", "line": 108, "exception": "Traceback (most recent call last):\n  File \"/Users/simba/Downloads/Personal-AI-Agent/main.py\", line 368, in process_request\n    response = await chat_service.process(message.content, message.parameters)\n                     ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nTypeError: ChatService.process() takes 2 positional arguments but 3 were given"}
{"timestamp": "2025-04-23T21:14:37.966525", "level": "INFO", "message": "Request: POST /assist - Time: 0.0034s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T21:14:56.131032", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T21:14:56.132410", "level": "ERROR", "message": "Error during LLMClient summarization: name 'model' is not defined", "module": "summarize", "function": "process", "line": 105, "exception": "Traceback (most recent call last):\n  File \"/Users/simba/Downloads/Personal-AI-Agent/services/summarize.py\", line 83, in process\n    model=model\n          ^^^^^\nNameError: name 'model' is not defined"}
{"timestamp": "2025-04-23T21:14:56.132613", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-23T21:14:56.132778", "level": "INFO", "message": "Request: POST /assist - Time: 0.0025s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T21:15:00.309147", "level": "INFO", "message": "Request: GET /todos - Time: 0.0018s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T21:15:00.313115", "level": "INFO", "message": "Request: GET /todos - Time: 0.0007s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T21:15:18.373455", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T21:15:18.375091", "level": "ERROR", "message": "Error in todo", "module": "logger", "function": "log_error", "line": 108, "exception": "Traceback (most recent call last):\n  File \"/Users/simba/Downloads/Personal-AI-Agent/main.py\", line 362, in process_request\n    response = await todo_service.process(message.content, message.parameters)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/simba/Downloads/Personal-AI-Agent/services/todo_manager.py\", line 98, in process\n    command = content.lower().strip()\n              ^^^^^^^^^^^^^\nAttributeError: 'dict' object has no attribute 'lower'"}
{"timestamp": "2025-04-23T21:15:18.375449", "level": "INFO", "message": "Request: POST /assist - Time: 0.0026s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T21:15:19.318296", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T21:15:19.319112", "level": "ERROR", "message": "Error in todo", "module": "logger", "function": "log_error", "line": 108, "exception": "Traceback (most recent call last):\n  File \"/Users/simba/Downloads/Personal-AI-Agent/main.py\", line 362, in process_request\n    response = await todo_service.process(message.content, message.parameters)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/simba/Downloads/Personal-AI-Agent/services/todo_manager.py\", line 98, in process\n    command = content.lower().strip()\n              ^^^^^^^^^^^^^\nAttributeError: 'dict' object has no attribute 'lower'"}
{"timestamp": "2025-04-23T21:15:19.319980", "level": "INFO", "message": "Request: POST /assist - Time: 0.0039s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T21:15:23.412667", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T21:15:24.012592", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-23T21:15:24.012808", "level": "INFO", "message": "Request: POST /assist - Time: 0.6011s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T21:15:30.690242", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T21:15:31.477252", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-23T21:15:31.477455", "level": "INFO", "message": "Request: POST /assist - Time: 0.7889s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T21:16:06.088852", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 224}
{"timestamp": "2025-04-23T21:16:06.089124", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 226}
{"timestamp": "2025-04-23T21:16:06.749361", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 218}
{"timestamp": "2025-04-23T21:16:19.038120", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T21:16:19.038779", "level": "ERROR", "message": "Error in chat", "module": "logger", "function": "log_error", "line": 108, "exception": "Traceback (most recent call last):\n  File \"/Users/simba/Downloads/Personal-AI-Agent/main.py\", line 368, in process_request\n    response = await chat_service.process(message.content, message.parameters)\n                     ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nTypeError: ChatService.process() takes 2 positional arguments but 3 were given"}
{"timestamp": "2025-04-23T21:16:19.039206", "level": "INFO", "message": "Request: POST /assist - Time: 0.0027s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T21:16:32.464889", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T21:16:35.386511", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-23T21:16:35.387044", "level": "INFO", "message": "Request: POST /assist - Time: 2.9231s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T21:17:01.315981", "level": "INFO", "message": "Request: GET /todos - Time: 0.0011s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T21:17:01.319794", "level": "INFO", "message": "Request: GET /todos - Time: 0.0008s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T21:17:30.206836", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T21:17:30.791483", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-23T21:17:30.792048", "level": "INFO", "message": "Request: POST /assist - Time: 0.5857s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T21:19:04.703772", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 224}
{"timestamp": "2025-04-23T21:19:04.704128", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 226}
{"timestamp": "2025-04-23T21:19:05.409385", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 218}
{"timestamp": "2025-04-23T21:19:11.876502", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 224}
{"timestamp": "2025-04-23T21:19:11.879476", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 226}
{"timestamp": "2025-04-23T21:19:12.534110", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 218}
{"timestamp": "2025-04-23T21:19:51.745003", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 224}
{"timestamp": "2025-04-23T21:19:51.754511", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 226}
{"timestamp": "2025-04-23T21:23:29.739081", "level": "INFO", "message": "Starting LLM Assistant API on 0.0.0.0:8000", "module": "main", "function": "<module>", "line": 527}
{"timestamp": "2025-04-23T21:23:30.305301", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 218}
{"timestamp": "2025-04-23T21:23:55.801912", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T21:23:56.449155", "level": "ERROR", "message": "Error in chat", "module": "logger", "function": "log_error", "line": 108, "exception": "Traceback (most recent call last):\n  File \"/Users/simba/Downloads/Personal-AI-Agent/main.py\", line 378, in process_request\n    if not response.get(\"metadata\"):\n           ^^^^^^^^^^^^\n  File \"/Users/simba/Downloads/Personal-AI-Agent/venv/lib/python3.13/site-packages/pydantic/main.py\", line 994, in __getattr__\n    raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}')\nAttributeError: 'ChatResponse' object has no attribute 'get'"}
{"timestamp": "2025-04-23T21:23:56.450198", "level": "INFO", "message": "Request: POST /assist - Time: 0.6500s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T21:24:33.845997", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 224}
{"timestamp": "2025-04-23T21:24:33.846456", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 226}
{"timestamp": "2025-04-23T21:24:34.429098", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 218}
{"timestamp": "2025-04-23T21:24:56.943459", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T21:24:57.399470", "level": "ERROR", "message": "Error in chat", "module": "logger", "function": "log_error", "line": 108, "exception": "Traceback (most recent call last):\n  File \"/Users/simba/Downloads/Personal-AI-Agent/main.py\", line 380, in process_request\n    response.metadata.request_type = message.type\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAttributeError: 'dict' object has no attribute 'request_type' and no __dict__ for setting new attributes"}
{"timestamp": "2025-04-23T21:24:57.399804", "level": "INFO", "message": "Request: POST /assist - Time: 0.4588s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T21:25:03.988061", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T21:25:04.637974", "level": "ERROR", "message": "Error in translate", "module": "logger", "function": "log_error", "line": 108, "exception": "Traceback (most recent call last):\n  File \"/Users/simba/Downloads/Personal-AI-Agent/main.py\", line 379, in process_request\n    response.metadata = {}\n    ^^^^^^^^^^^^^^^^^\nAttributeError: 'dict' object has no attribute 'metadata' and no __dict__ for setting new attributes"}
{"timestamp": "2025-04-23T21:25:04.638554", "level": "INFO", "message": "Request: POST /assist - Time: 0.6515s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T21:25:12.447247", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T21:25:13.240169", "level": "ERROR", "message": "Error in code", "module": "logger", "function": "log_error", "line": 108, "exception": "Traceback (most recent call last):\n  File \"/Users/simba/Downloads/Personal-AI-Agent/main.py\", line 379, in process_request\n    response.metadata = {}\n    ^^^^^^^^^^^^^^^^^\nAttributeError: 'dict' object has no attribute 'metadata' and no __dict__ for setting new attributes"}
{"timestamp": "2025-04-23T21:25:13.241040", "level": "INFO", "message": "Request: POST /assist - Time: 0.7946s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T21:25:43.832042", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 224}
{"timestamp": "2025-04-23T21:25:43.832310", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 226}
{"timestamp": "2025-04-23T21:25:44.427082", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 218}
{"timestamp": "2025-04-23T21:25:59.547796", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T21:26:00.032451", "level": "ERROR", "message": "Error in translate", "module": "logger", "function": "log_error", "line": 108, "exception": "Traceback (most recent call last):\n  File \"/Users/simba/Downloads/Personal-AI-Agent/main.py\", line 394, in process_request\n    log_response(\n    ~~~~~~~~~~~~^\n        request_type=message.type,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<2 lines>...\n        metadata=metadata\n        ^^^^^^^^^^^^^^^^^\n    )\n    ^\nTypeError: log_response() got an unexpected keyword argument 'request_type'"}
{"timestamp": "2025-04-23T21:26:00.032989", "level": "INFO", "message": "Request: POST /assist - Time: 0.4864s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T21:26:10.772273", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T21:26:11.600623", "level": "ERROR", "message": "Error in code", "module": "logger", "function": "log_error", "line": 108, "exception": "Traceback (most recent call last):\n  File \"/Users/simba/Downloads/Personal-AI-Agent/main.py\", line 394, in process_request\n    log_response(\n    ~~~~~~~~~~~~^\n        request_type=message.type,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<2 lines>...\n        metadata=metadata\n        ^^^^^^^^^^^^^^^^^\n    )\n    ^\nTypeError: log_response() got an unexpected keyword argument 'request_type'"}
{"timestamp": "2025-04-23T21:26:11.601111", "level": "INFO", "message": "Request: POST /assist - Time: 0.8300s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T21:26:51.835219", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 224}
{"timestamp": "2025-04-23T21:26:51.835713", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 226}
{"timestamp": "2025-04-23T21:26:52.419423", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 218}
{"timestamp": "2025-04-23T21:26:57.530142", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T21:26:58.401799", "level": "ERROR", "message": "Error in code", "module": "logger", "function": "log_error", "line": 108, "exception": "Traceback (most recent call last):\n  File \"/Users/simba/Downloads/Personal-AI-Agent/main.py\", line 394, in process_request\n    log_response(\n    ~~~~~~~~~~~~^\n        request_type=message.type,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<2 lines>...\n        metadata=metadata\n        ^^^^^^^^^^^^^^^^^\n    )\n    ^\nTypeError: log_response() got an unexpected keyword argument 'request_type'"}
{"timestamp": "2025-04-23T21:26:58.402280", "level": "INFO", "message": "Request: POST /assist - Time: 0.8740s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T21:26:59.115897", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T21:26:59.935262", "level": "ERROR", "message": "Error in code", "module": "logger", "function": "log_error", "line": 108, "exception": "Traceback (most recent call last):\n  File \"/Users/simba/Downloads/Personal-AI-Agent/main.py\", line 394, in process_request\n    log_response(\n    ~~~~~~~~~~~~^\n        request_type=message.type,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<2 lines>...\n        metadata=metadata\n        ^^^^^^^^^^^^^^^^^\n    )\n    ^\nTypeError: log_response() got an unexpected keyword argument 'request_type'"}
{"timestamp": "2025-04-23T21:26:59.935670", "level": "INFO", "message": "Request: POST /assist - Time: 0.8204s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T21:27:28.199027", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 224}
{"timestamp": "2025-04-23T21:27:28.199321", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 226}
{"timestamp": "2025-04-23T21:27:28.765378", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 218}
{"timestamp": "2025-04-23T21:27:33.526501", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T21:27:34.451961", "level": "ERROR", "message": "Error in code", "module": "logger", "function": "log_error", "line": 108, "exception": "Traceback (most recent call last):\n  File \"/Users/simba/Downloads/Personal-AI-Agent/main.py\", line 394, in process_request\n    log_response(\n    ~~~~~~~~~~~~^\n        service=message.type,\n        ^^^^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n        metadata=metadata\n        ^^^^^^^^^^^^^^^^^\n    )\n    ^\nTypeError: log_response() got an unexpected keyword argument 'user'"}
{"timestamp": "2025-04-23T21:27:34.452490", "level": "INFO", "message": "Request: POST /assist - Time: 0.9274s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T21:27:39.649665", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T21:27:40.084156", "level": "ERROR", "message": "Error in translate", "module": "logger", "function": "log_error", "line": 108, "exception": "Traceback (most recent call last):\n  File \"/Users/simba/Downloads/Personal-AI-Agent/main.py\", line 394, in process_request\n    log_response(\n    ~~~~~~~~~~~~^\n        service=message.type,\n        ^^^^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n        metadata=metadata\n        ^^^^^^^^^^^^^^^^^\n    )\n    ^\nTypeError: log_response() got an unexpected keyword argument 'user'"}
{"timestamp": "2025-04-23T21:27:40.085598", "level": "INFO", "message": "Request: POST /assist - Time: 0.4369s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T21:27:47.900113", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T21:27:52.583317", "level": "ERROR", "message": "Error in email", "module": "logger", "function": "log_error", "line": 108, "exception": "Traceback (most recent call last):\n  File \"/Users/simba/Downloads/Personal-AI-Agent/main.py\", line 394, in process_request\n    log_response(\n    ~~~~~~~~~~~~^\n        service=message.type,\n        ^^^^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n        metadata=metadata\n        ^^^^^^^^^^^^^^^^^\n    )\n    ^\nTypeError: log_response() got an unexpected keyword argument 'user'"}
{"timestamp": "2025-04-23T21:27:52.583663", "level": "INFO", "message": "Request: POST /assist - Time: 4.6856s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T21:27:58.977055", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T21:27:59.639294", "level": "ERROR", "message": "Error in chat", "module": "logger", "function": "log_error", "line": 108, "exception": "Traceback (most recent call last):\n  File \"/Users/simba/Downloads/Personal-AI-Agent/main.py\", line 390, in process_request\n    content = response.content\n              ^^^^^^^^^^^^^^^^\n  File \"/Users/simba/Downloads/Personal-AI-Agent/venv/lib/python3.13/site-packages/pydantic/main.py\", line 994, in __getattr__\n    raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}')\nAttributeError: 'ChatResponse' object has no attribute 'content'"}
{"timestamp": "2025-04-23T21:27:59.639901", "level": "INFO", "message": "Request: POST /assist - Time: 0.6636s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T21:28:07.768222", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 224}
{"timestamp": "2025-04-23T21:28:07.768625", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 226}
{"timestamp": "2025-04-23T21:28:10.680745", "level": "INFO", "message": "Starting LLM Assistant API on 0.0.0.0:8000", "module": "main", "function": "<module>", "line": 535}
{"timestamp": "2025-04-23T21:28:11.258165", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 218}
{"timestamp": "2025-04-23T21:28:33.390758", "level": "INFO", "message": "Starting LLM Assistant API on 0.0.0.0:8000", "module": "main", "function": "<module>", "line": 535}
{"timestamp": "2025-04-23T21:28:33.957316", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 218}
{"timestamp": "2025-04-23T21:28:56.939325", "level": "INFO", "message": "Starting LLM Assistant API on 0.0.0.0:8000", "module": "main", "function": "<module>", "line": 535}
{"timestamp": "2025-04-23T21:29:42.522609", "level": "INFO", "message": "Starting LLM Assistant API on 0.0.0.0:8000", "module": "main", "function": "<module>", "line": 535}
{"timestamp": "2025-04-23T21:29:43.120349", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 218}
{"timestamp": "2025-04-23T21:30:16.454059", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T21:30:16.912298", "level": "ERROR", "message": "Error in translate", "module": "logger", "function": "log_error", "line": 108, "exception": "Traceback (most recent call last):\n  File \"/Users/simba/Downloads/Personal-AI-Agent/main.py\", line 394, in process_request\n    log_response(\n    ~~~~~~~~~~~~^\n        service=message.type,\n        ^^^^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n        metadata=metadata\n        ^^^^^^^^^^^^^^^^^\n    )\n    ^\nTypeError: log_response() got an unexpected keyword argument 'user'"}
{"timestamp": "2025-04-23T21:30:16.913058", "level": "INFO", "message": "Request: POST /assist - Time: 0.4602s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T21:30:23.502672", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T21:30:24.331904", "level": "ERROR", "message": "Error in code", "module": "logger", "function": "log_error", "line": 108, "exception": "Traceback (most recent call last):\n  File \"/Users/simba/Downloads/Personal-AI-Agent/main.py\", line 394, in process_request\n    log_response(\n    ~~~~~~~~~~~~^\n        service=message.type,\n        ^^^^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n        metadata=metadata\n        ^^^^^^^^^^^^^^^^^\n    )\n    ^\nTypeError: log_response() got an unexpected keyword argument 'user'"}
{"timestamp": "2025-04-23T21:30:24.332377", "level": "INFO", "message": "Request: POST /assist - Time: 0.8304s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T21:30:25.837139", "level": "INFO", "message": "Request: GET /todos - Time: 0.0013s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T21:30:25.840805", "level": "INFO", "message": "Request: GET /todos - Time: 0.0008s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T21:30:32.873777", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T21:30:37.548193", "level": "ERROR", "message": "Error in email", "module": "logger", "function": "log_error", "line": 108, "exception": "Traceback (most recent call last):\n  File \"/Users/simba/Downloads/Personal-AI-Agent/main.py\", line 394, in process_request\n    log_response(\n    ~~~~~~~~~~~~^\n        service=message.type,\n        ^^^^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n        metadata=metadata\n        ^^^^^^^^^^^^^^^^^\n    )\n    ^\nTypeError: log_response() got an unexpected keyword argument 'user'"}
{"timestamp": "2025-04-23T21:30:37.549249", "level": "INFO", "message": "Request: POST /assist - Time: 4.6765s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T21:30:44.606722", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T21:30:45.224657", "level": "ERROR", "message": "Error in chat", "module": "logger", "function": "log_error", "line": 108, "exception": "Traceback (most recent call last):\n  File \"/Users/simba/Downloads/Personal-AI-Agent/main.py\", line 390, in process_request\n    content = response.content\n              ^^^^^^^^^^^^^^^^\n  File \"/Users/simba/Downloads/Personal-AI-Agent/venv/lib/python3.13/site-packages/pydantic/main.py\", line 994, in __getattr__\n    raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}')\nAttributeError: 'ChatResponse' object has no attribute 'content'"}
{"timestamp": "2025-04-23T21:30:45.225453", "level": "INFO", "message": "Request: POST /assist - Time: 0.6207s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T21:31:38.131083", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 224}
{"timestamp": "2025-04-23T21:31:38.131379", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 226}
{"timestamp": "2025-04-23T21:31:38.727943", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 218}
{"timestamp": "2025-04-23T21:38:40.665958", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-23T21:38:41.705729", "level": "ERROR", "message": "Error in code", "module": "logger", "function": "log_error", "line": 108, "exception": "Traceback (most recent call last):\n  File \"/Users/simba/Downloads/Personal-AI-Agent/main.py\", line 394, in process_request\n    log_response(\n    ~~~~~~~~~~~~^\n        content=message.content,\n        ^^^^^^^^^^^^^^^^^^^^^^^^\n        metadata=metadata\n        ^^^^^^^^^^^^^^^^^\n    )\n    ^\nTypeError: log_response() got an unexpected keyword argument 'content'"}
{"timestamp": "2025-04-23T21:38:41.706098", "level": "INFO", "message": "Request: POST /assist - Time: 1.0415s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-23T21:39:13.074427", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 224}
{"timestamp": "2025-04-23T21:39:13.074657", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 226}
{"timestamp": "2025-04-23T21:39:13.667827", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 218}
{"timestamp": "2025-04-23T21:39:28.315795", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 224}
{"timestamp": "2025-04-23T21:39:28.318399", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 226}
{"timestamp": "2025-04-23T21:39:28.879424", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 218}
{"timestamp": "2025-04-24T04:00:24.927636", "level": "INFO", "message": "Starting LLM Assistant API on 0.0.0.0:8000", "module": "main", "function": "<module>", "line": 545}
{"timestamp": "2025-04-24T04:00:25.504604", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 218}
{"timestamp": "2025-04-24T04:00:46.044445", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T04:00:46.537318", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T04:00:46.537771", "level": "INFO", "message": "Request: POST /assist - Time: 0.4954s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T04:00:55.520773", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T04:01:01.595721", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T04:01:01.596460", "level": "INFO", "message": "Request: POST /assist - Time: 6.0768s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T04:01:17.976400", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T04:01:19.202766", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T04:01:19.203010", "level": "INFO", "message": "Request: POST /assist - Time: 1.2285s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T04:01:27.118237", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T04:01:27.500110", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T04:01:27.500667", "level": "INFO", "message": "Request: POST /assist - Time: 0.3838s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T04:02:06.633127", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T04:02:07.025211", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T04:02:07.025430", "level": "INFO", "message": "Request: POST /assist - Time: 0.3938s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T04:06:07.075729", "level": "ERROR", "message": "Error during LLMClient summarization: GeminiClient.generate_response() got an unexpected keyword argument 'model'", "module": "summarize", "function": "process", "line": 105, "exception": "Traceback (most recent call last):\n  File \"/Users/simba/Downloads/Personal-AI-Agent/services/summarize.py\", line 78, in process\n    response = await self.gemini_client.generate_response(\n                     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        prompt=text_to_summarize,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n        model=\"gemini-pro\"\n        ^^^^^^^^^^^^^^^^^^\n    )\n    ^\nTypeError: GeminiClient.generate_response() got an unexpected keyword argument 'model'"}
{"timestamp": "2025-04-24T04:06:19.454060", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 224}
{"timestamp": "2025-04-24T04:06:19.454458", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 226}
{"timestamp": "2025-04-24T04:06:20.056732", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 218}
{"timestamp": "2025-04-24T04:06:23.950378", "level": "INFO", "message": "Summary generated via LLMClient.", "module": "summarize", "function": "process", "line": 86}
{"timestamp": "2025-04-24T04:07:56.951456", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 224}
{"timestamp": "2025-04-24T04:07:56.956585", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 226}
{"timestamp": "2025-04-24T04:07:57.565579", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 218}
{"timestamp": "2025-04-24T04:08:03.222555", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 224}
{"timestamp": "2025-04-24T04:08:03.225778", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 226}
{"timestamp": "2025-04-24T04:08:03.791338", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 218}
{"timestamp": "2025-04-24T04:09:04.304515", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 224}
{"timestamp": "2025-04-24T04:09:04.308885", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 226}
{"timestamp": "2025-04-24T04:09:04.902856", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 218}
{"timestamp": "2025-04-24T04:09:09.953508", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 224}
{"timestamp": "2025-04-24T04:09:09.958625", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 226}
{"timestamp": "2025-04-24T04:09:10.546442", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 218}
{"timestamp": "2025-04-24T04:09:20.820921", "level": "INFO", "message": "Request: GET /todos - Time: 0.0013s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T04:09:20.823862", "level": "INFO", "message": "Request: GET /todos - Time: 0.0008s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T04:09:27.722926", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T04:09:32.586882", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T04:09:32.587173", "level": "INFO", "message": "Request: POST /assist - Time: 4.8654s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T04:09:47.793944", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T04:09:48.471900", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T04:09:48.472167", "level": "INFO", "message": "Request: POST /assist - Time: 0.6790s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T04:09:57.740602", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T04:09:58.008256", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T04:09:58.008491", "level": "INFO", "message": "Request: POST /assist - Time: 0.2686s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T04:10:04.948205", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T04:10:05.270398", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T04:10:05.270737", "level": "INFO", "message": "Request: POST /assist - Time: 0.3239s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T04:10:14.945289", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T04:10:15.399937", "level": "INFO", "message": "Summary generated via LLMClient.", "module": "summarize", "function": "process", "line": 86}
{"timestamp": "2025-04-24T04:10:15.400135", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T04:10:15.400539", "level": "INFO", "message": "Request: POST /assist - Time: 0.4558s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T04:10:33.836076", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T04:10:34.266464", "level": "INFO", "message": "Summary generated via LLMClient.", "module": "summarize", "function": "process", "line": 86}
{"timestamp": "2025-04-24T04:10:34.266557", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T04:10:34.266746", "level": "INFO", "message": "Request: POST /assist - Time: 0.4314s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T04:10:41.324638", "level": "INFO", "message": "Request: GET /todos - Time: 0.0020s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T04:10:41.329721", "level": "INFO", "message": "Request: GET /todos - Time: 0.0011s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T04:10:58.440179", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T04:10:58.441627", "level": "ERROR", "message": "Error in todo", "module": "logger", "function": "log_error", "line": 108, "exception": "Traceback (most recent call last):\n  File \"/Users/simba/Downloads/Personal-AI-Agent/main.py\", line 362, in process_request\n    response = await todo_service.process(message.content, message.parameters)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/simba/Downloads/Personal-AI-Agent/services/todo_manager.py\", line 98, in process\n    command = content.lower().strip()\n              ^^^^^^^^^^^^^\nAttributeError: 'dict' object has no attribute 'lower'"}
{"timestamp": "2025-04-24T04:10:58.442253", "level": "INFO", "message": "Request: POST /assist - Time: 0.0027s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T04:11:08.342743", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T04:11:08.674581", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T04:11:08.674799", "level": "INFO", "message": "Request: POST /assist - Time: 0.3332s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T04:11:55.142259", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T04:11:55.565621", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T04:11:55.565807", "level": "INFO", "message": "Request: POST /assist - Time: 0.4242s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T04:11:59.335431", "level": "INFO", "message": "Request: GET /todos - Time: 0.0004s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T04:11:59.337551", "level": "INFO", "message": "Request: GET /todos - Time: 0.0005s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T04:12:03.347018", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T04:12:03.670775", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T04:12:03.670961", "level": "INFO", "message": "Request: POST /assist - Time: 0.3249s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T04:13:46.934704", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 224}
{"timestamp": "2025-04-24T04:13:46.934956", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 226}
{"timestamp": "2025-04-24T04:13:48.434162", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 218}
{"timestamp": "2025-04-24T04:14:34.612090", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 224}
{"timestamp": "2025-04-24T04:14:34.619564", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 226}
{"timestamp": "2025-04-24T04:14:35.191685", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 218}
{"timestamp": "2025-04-24T04:14:48.422922", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 224}
{"timestamp": "2025-04-24T04:14:48.427201", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 226}
{"timestamp": "2025-04-24T04:14:48.993443", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 218}
{"timestamp": "2025-04-24T04:15:10.106164", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 224}
{"timestamp": "2025-04-24T04:15:10.113720", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 226}
{"timestamp": "2025-04-24T04:15:10.755273", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 218}
{"timestamp": "2025-04-24T04:15:14.297148", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 224}
{"timestamp": "2025-04-24T04:15:14.306447", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 226}
{"timestamp": "2025-04-24T04:15:16.620648", "level": "INFO", "message": "Starting LLM Assistant API on 0.0.0.0:8000", "module": "main", "function": "<module>", "line": 545}
{"timestamp": "2025-04-24T04:15:17.184670", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 218}
{"timestamp": "2025-04-24T04:15:26.062189", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T04:15:26.411866", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T04:15:26.412584", "level": "INFO", "message": "Request: POST /assist - Time: 0.3539s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T04:15:35.947110", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T04:15:36.292639", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T04:15:36.293247", "level": "INFO", "message": "Request: POST /assist - Time: 0.3476s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T04:16:12.762082", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T04:16:13.154781", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T04:16:13.155216", "level": "INFO", "message": "Request: POST /assist - Time: 0.3956s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T04:30:31.414952", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T04:30:31.823259", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T04:30:31.823543", "level": "INFO", "message": "Request: POST /assist - Time: 0.4104s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T04:31:40.452453", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T04:31:40.822943", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T04:31:40.823358", "level": "INFO", "message": "Request: POST /assist - Time: 0.3722s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T04:35:42.289670", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T04:35:42.674466", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T04:35:42.674718", "level": "INFO", "message": "Request: POST /assist - Time: 0.3857s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T04:39:15.445826", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T04:39:15.789348", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T04:39:15.789704", "level": "INFO", "message": "Request: POST /assist - Time: 0.3449s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T04:43:14.283636", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 224}
{"timestamp": "2025-04-24T04:43:14.283883", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 226}
{"timestamp": "2025-04-24T04:43:14.937725", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 218}
{"timestamp": "2025-04-24T04:43:28.773442", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 224}
{"timestamp": "2025-04-24T04:43:28.777606", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 226}
{"timestamp": "2025-04-24T04:43:29.340704", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 218}
{"timestamp": "2025-04-24T04:43:50.028155", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T04:43:50.392471", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T04:43:50.393126", "level": "INFO", "message": "Request: POST /assist - Time: 0.3672s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T04:44:06.890835", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T04:44:07.287951", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T04:44:07.288148", "level": "INFO", "message": "Request: POST /assist - Time: 0.3981s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T04:45:23.114353", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 224}
{"timestamp": "2025-04-24T04:45:23.114615", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 226}
{"timestamp": "2025-04-24T04:45:23.673259", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 218}
{"timestamp": "2025-04-24T04:45:37.519422", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 224}
{"timestamp": "2025-04-24T04:45:37.525245", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 226}
{"timestamp": "2025-04-24T04:45:38.111255", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 218}
{"timestamp": "2025-04-24T04:45:52.962653", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T04:45:53.426236", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T04:45:53.426604", "level": "INFO", "message": "Request: POST /assist - Time: 0.4655s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T04:46:13.069541", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 224}
{"timestamp": "2025-04-24T04:46:13.069815", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 226}
{"timestamp": "2025-04-24T04:46:15.284728", "level": "INFO", "message": "Starting LLM Assistant API on 0.0.0.0:8000", "module": "main", "function": "<module>", "line": 545}
{"timestamp": "2025-04-24T04:46:15.848203", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 218}
{"timestamp": "2025-04-24T04:46:30.015642", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T04:46:30.396514", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T04:46:30.396790", "level": "INFO", "message": "Request: POST /assist - Time: 0.3828s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T04:48:09.194547", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 224}
{"timestamp": "2025-04-24T04:48:09.194822", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 226}
{"timestamp": "2025-04-24T04:48:09.871228", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 218}
{"timestamp": "2025-04-24T04:48:34.722106", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 224}
{"timestamp": "2025-04-24T04:48:34.727516", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 226}
{"timestamp": "2025-04-24T04:48:35.333412", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 218}
{"timestamp": "2025-04-24T04:48:46.791328", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T04:48:47.225197", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T04:48:47.225425", "level": "INFO", "message": "Request: POST /assist - Time: 0.4353s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T04:52:08.105109", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 224}
{"timestamp": "2025-04-24T04:52:08.105492", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 226}
{"timestamp": "2025-04-24T04:52:08.756153", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 218}
{"timestamp": "2025-04-24T04:52:23.857726", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T04:52:24.366242", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T04:52:24.366582", "level": "INFO", "message": "Request: POST /assist - Time: 0.5112s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T04:53:23.645071", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 224}
{"timestamp": "2025-04-24T04:53:23.645390", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 226}
{"timestamp": "2025-04-24T04:53:24.293190", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 218}
{"timestamp": "2025-04-24T04:53:31.543673", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T04:53:31.899678", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T04:53:31.900218", "level": "INFO", "message": "Request: POST /assist - Time: 0.3583s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T04:54:46.152801", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 224}
{"timestamp": "2025-04-24T04:54:46.153239", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 226}
{"timestamp": "2025-04-24T04:54:46.846586", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 218}
{"timestamp": "2025-04-24T04:54:50.481109", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 224}
{"timestamp": "2025-04-24T04:54:50.486675", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 226}
{"timestamp": "2025-04-24T04:54:51.064771", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 218}
{"timestamp": "2025-04-24T04:54:59.397004", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T04:54:59.814964", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T04:54:59.815527", "level": "INFO", "message": "Request: POST /assist - Time: 0.4205s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T04:55:35.525578", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 224}
{"timestamp": "2025-04-24T04:55:35.525914", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 226}
{"timestamp": "2025-04-24T04:55:36.237882", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 218}
{"timestamp": "2025-04-24T04:56:08.069165", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T04:56:08.195839", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T04:56:08.196088", "level": "INFO", "message": "Request: POST /assist - Time: 0.1291s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T04:57:02.055121", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 224}
{"timestamp": "2025-04-24T04:57:02.055457", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 226}
{"timestamp": "2025-04-24T04:57:02.730147", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 218}
{"timestamp": "2025-04-24T04:57:08.648963", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T04:57:09.041403", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T04:57:09.041827", "level": "INFO", "message": "Request: POST /assist - Time: 0.3955s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T04:57:58.400462", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 224}
{"timestamp": "2025-04-24T04:57:58.400908", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 226}
{"timestamp": "2025-04-24T04:57:59.057889", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 218}
{"timestamp": "2025-04-24T04:58:15.325341", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 224}
{"timestamp": "2025-04-24T04:58:15.334728", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 226}
{"timestamp": "2025-04-24T04:58:17.664671", "level": "INFO", "message": "Starting LLM Assistant API on 0.0.0.0:8000", "module": "main", "function": "<module>", "line": 545}
{"timestamp": "2025-04-24T04:58:18.229272", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 218}
{"timestamp": "2025-04-24T04:58:28.295644", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T04:58:28.813369", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T04:58:28.813870", "level": "INFO", "message": "Request: POST /assist - Time: 0.5199s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T04:59:38.569690", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 224}
{"timestamp": "2025-04-24T04:59:38.570006", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 226}
{"timestamp": "2025-04-24T04:59:39.236656", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 218}
{"timestamp": "2025-04-24T04:59:47.396740", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T04:59:47.943485", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T04:59:47.944052", "level": "INFO", "message": "Request: POST /assist - Time: 0.5489s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T05:35:17.933102", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 224}
{"timestamp": "2025-04-24T05:35:17.933622", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 226}
{"timestamp": "2025-04-24T05:35:18.614870", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 218}
{"timestamp": "2025-04-24T05:35:23.411499", "level": "INFO", "message": "Starting LLM Assistant API on 0.0.0.0:8000", "module": "main", "function": "<module>", "line": 545}
{"timestamp": "2025-04-24T05:35:51.278242", "level": "INFO", "message": "Starting LLM Assistant API on 0.0.0.0:8000", "module": "main", "function": "<module>", "line": 545}
{"timestamp": "2025-04-24T05:35:51.844997", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 218}
{"timestamp": "2025-04-24T05:36:32.087420", "level": "INFO", "message": "Starting LLM Assistant API on 0.0.0.0:8000", "module": "main", "function": "<module>", "line": 545}
{"timestamp": "2025-04-24T05:36:54.417481", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T05:36:54.824461", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T05:36:54.824742", "level": "INFO", "message": "Request: POST /assist - Time: 0.4087s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T05:37:06.516388", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T05:37:07.144798", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T05:37:07.145024", "level": "INFO", "message": "Request: POST /assist - Time: 0.6295s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T05:37:13.668649", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T05:37:13.981436", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T05:37:13.981680", "level": "INFO", "message": "Request: POST /assist - Time: 0.3139s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T05:37:15.373293", "level": "INFO", "message": "Request: GET /todos - Time: 0.0008s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T05:37:15.376226", "level": "INFO", "message": "Request: GET /todos - Time: 0.0006s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T05:37:32.937667", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T05:37:33.399653", "level": "INFO", "message": "Summary generated via LLMClient.", "module": "summarize", "function": "process", "line": 86}
{"timestamp": "2025-04-24T05:37:33.399762", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T05:37:33.399989", "level": "INFO", "message": "Request: POST /assist - Time: 0.4630s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T05:39:00.522161", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 224}
{"timestamp": "2025-04-24T05:39:00.522446", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 226}
{"timestamp": "2025-04-24T05:39:57.443439", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 218}
{"timestamp": "2025-04-24T05:40:15.339497", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T05:40:15.707177", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T05:40:15.707415", "level": "INFO", "message": "Request: POST /assist - Time: 0.3693s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T05:51:04.129818", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 224}
{"timestamp": "2025-04-24T05:51:04.130343", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 226}
{"timestamp": "2025-04-24T05:51:04.809737", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 218}
{"timestamp": "2025-04-24T05:51:08.897391", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T05:51:09.320811", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T05:51:09.321284", "level": "INFO", "message": "Request: POST /assist - Time: 0.4272s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T05:51:18.381722", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T05:51:18.867739", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T05:51:18.868402", "level": "INFO", "message": "Request: POST /assist - Time: 0.4874s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T05:53:44.431337", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T05:53:44.962041", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T05:53:44.962256", "level": "INFO", "message": "Request: POST /assist - Time: 0.5323s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T05:55:38.279219", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 224}
{"timestamp": "2025-04-24T05:55:38.279440", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 226}
{"timestamp": "2025-04-24T05:55:39.005699", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 218}
{"timestamp": "2025-04-24T05:55:41.430915", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 224}
{"timestamp": "2025-04-24T05:55:41.435856", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 226}
{"timestamp": "2025-04-24T05:56:10.805454", "level": "INFO", "message": "Starting LLM Assistant API on 0.0.0.0:8000", "module": "main", "function": "<module>", "line": 545}
{"timestamp": "2025-04-24T05:56:11.379885", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 218}
{"timestamp": "2025-04-24T05:56:24.125078", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T05:56:24.574577", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T05:56:24.574882", "level": "INFO", "message": "Request: POST /assist - Time: 0.4523s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T05:57:38.043761", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T05:57:38.445495", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T05:57:38.445752", "level": "INFO", "message": "Request: POST /assist - Time: 0.4025s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T05:58:34.934280", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T05:58:35.302359", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T05:58:35.302598", "level": "INFO", "message": "Request: POST /assist - Time: 0.3691s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T05:58:46.160583", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T05:58:47.254525", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T05:58:47.254724", "level": "INFO", "message": "Request: POST /assist - Time: 1.0957s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T06:05:48.314526", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T06:05:48.647061", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T06:05:48.647402", "level": "INFO", "message": "Request: POST /assist - Time: 0.3339s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T06:08:03.630306", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T06:08:03.937143", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T06:08:03.937685", "level": "INFO", "message": "Request: POST /assist - Time: 0.3079s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T06:09:08.189935", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T06:09:08.548152", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T06:09:08.548433", "level": "INFO", "message": "Request: POST /assist - Time: 0.3593s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T06:09:16.947550", "level": "INFO", "message": "Request: GET /todos - Time: 0.0005s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T06:09:16.949405", "level": "INFO", "message": "Request: GET /todos - Time: 0.0005s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T06:12:35.122227", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T06:12:35.619330", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T06:12:35.619538", "level": "INFO", "message": "Request: POST /assist - Time: 0.4986s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T06:13:03.489312", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T06:13:05.148257", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T06:13:05.148707", "level": "INFO", "message": "Request: POST /assist - Time: 1.6598s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T06:14:12.237634", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T06:14:13.735616", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T06:14:13.735828", "level": "INFO", "message": "Request: POST /assist - Time: 1.4989s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T06:18:44.654549", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T06:18:44.993406", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T06:18:44.993599", "level": "INFO", "message": "Request: POST /assist - Time: 0.3398s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T06:19:08.075228", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T06:19:08.414974", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T06:19:08.415163", "level": "INFO", "message": "Request: POST /assist - Time: 0.3407s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T06:23:13.503914", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T06:23:14.000125", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T06:23:14.000621", "level": "INFO", "message": "Request: POST /assist - Time: 0.4975s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T06:23:23.992649", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T06:23:24.946088", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T06:23:24.946355", "level": "INFO", "message": "Request: POST /assist - Time: 0.9555s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T16:25:00.539311", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T16:25:00.975085", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T16:25:00.975414", "level": "INFO", "message": "Request: POST /assist - Time: 0.4385s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T16:25:31.329819", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T16:25:31.839083", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T16:25:31.839305", "level": "INFO", "message": "Request: POST /assist - Time: 0.5106s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T16:26:02.224598", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T16:26:02.807459", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T16:26:02.807679", "level": "INFO", "message": "Request: POST /assist - Time: 0.5843s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T16:26:59.592708", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T16:27:00.301889", "level": "INFO", "message": "Summary generated via LLMClient.", "module": "summarize", "function": "process", "line": 86}
{"timestamp": "2025-04-24T16:27:00.302092", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T16:27:00.302665", "level": "INFO", "message": "Request: POST /assist - Time: 0.7115s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T16:27:04.159554", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T16:27:05.014083", "level": "INFO", "message": "Summary generated via LLMClient.", "module": "summarize", "function": "process", "line": 86}
{"timestamp": "2025-04-24T16:27:05.014318", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T16:27:05.015004", "level": "INFO", "message": "Request: POST /assist - Time: 0.8559s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T16:27:11.145236", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T16:27:11.972527", "level": "INFO", "message": "Summary generated via LLMClient.", "module": "summarize", "function": "process", "line": 86}
{"timestamp": "2025-04-24T16:27:11.972613", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T16:27:11.972802", "level": "INFO", "message": "Request: POST /assist - Time: 0.8294s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T16:27:17.463981", "level": "INFO", "message": "Request: GET /todos - Time: 0.0012s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T16:27:17.466892", "level": "INFO", "message": "Request: GET /todos - Time: 0.0007s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T16:27:29.567168", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T16:27:31.457878", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T16:27:31.458298", "level": "INFO", "message": "Request: POST /assist - Time: 1.8917s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T16:27:50.425688", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T16:27:52.207897", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T16:27:52.208120", "level": "INFO", "message": "Request: POST /assist - Time: 1.7830s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T16:28:25.738366", "level": "INFO", "message": "Request: GET /todos - Time: 0.0006s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T16:28:25.740799", "level": "INFO", "message": "Request: GET /todos - Time: 0.0003s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T16:33:22.923910", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T16:33:23.350180", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T16:33:23.350381", "level": "INFO", "message": "Request: POST /assist - Time: 0.4274s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T16:34:44.664010", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T16:34:44.664094", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T16:34:44.664366", "level": "INFO", "message": "Request: POST /assist - Time: 0.0010s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T16:34:51.617486", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T16:34:51.617622", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T16:34:51.618075", "level": "INFO", "message": "Request: POST /assist - Time: 0.0016s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T16:34:52.593110", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T16:34:52.593239", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T16:34:52.593512", "level": "INFO", "message": "Request: POST /assist - Time: 0.0011s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T16:35:00.094719", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T16:35:00.503319", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T16:35:00.503606", "level": "INFO", "message": "Request: POST /assist - Time: 0.4096s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T16:35:59.288513", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T16:35:59.692945", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T16:35:59.693157", "level": "INFO", "message": "Request: POST /assist - Time: 0.4052s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T16:36:12.452145", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T16:36:12.844500", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T16:36:12.845293", "level": "INFO", "message": "Request: POST /assist - Time: 0.3943s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T16:36:19.763855", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T16:36:20.212076", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T16:36:20.212433", "level": "INFO", "message": "Request: POST /assist - Time: 0.4492s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T16:36:26.424690", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T16:36:26.916835", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T16:36:26.917239", "level": "INFO", "message": "Request: POST /assist - Time: 0.4935s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T16:36:37.779702", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T16:36:38.218952", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T16:36:38.219182", "level": "INFO", "message": "Request: POST /assist - Time: 0.4401s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T16:40:31.908125", "level": "INFO", "message": "Request: GET /todos - Time: 0.0005s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T16:40:31.910074", "level": "INFO", "message": "Request: GET /todos - Time: 0.0003s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T16:42:15.643140", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T16:42:15.643275", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T16:42:15.643549", "level": "INFO", "message": "Request: POST /assist - Time: 0.0010s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T16:45:32.048241", "level": "INFO", "message": "Successful login for user: testuser", "module": "main", "function": "login_for_access_token", "line": 284}
{"timestamp": "2025-04-24T16:45:32.048672", "level": "INFO", "message": "Request: POST /token - Time: 0.2439s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T16:45:38.675209", "level": "INFO", "message": "Successful login for user: testuser", "module": "main", "function": "login_for_access_token", "line": 284}
{"timestamp": "2025-04-24T16:45:38.675523", "level": "INFO", "message": "Request: POST /token - Time: 0.2356s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T16:50:39.804815", "level": "INFO", "message": "Successful login for user: testuser", "module": "main", "function": "login_for_access_token", "line": 284}
{"timestamp": "2025-04-24T16:50:39.805158", "level": "INFO", "message": "Request: POST /token - Time: 0.2445s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T17:05:58.501827", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 224}
{"timestamp": "2025-04-24T17:05:58.502538", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 226}
{"timestamp": "2025-04-24T17:05:59.213610", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 221}
{"timestamp": "2025-04-24T17:27:00.031362", "level": "INFO", "message": "Successful login for user: testuser", "module": "main", "function": "login_for_access_token", "line": 287}
{"timestamp": "2025-04-24T17:27:00.031777", "level": "INFO", "message": "Request: POST /token - Time: 0.2316s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T17:27:10.313749", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T17:27:10.860792", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T17:27:10.860998", "level": "INFO", "message": "Request: POST /assist - Time: 0.5497s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T17:27:17.924364", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T17:27:18.760479", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T17:27:18.760681", "level": "INFO", "message": "Request: POST /assist - Time: 0.8376s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T17:33:11.056755", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T17:33:11.549843", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T17:33:11.550097", "level": "INFO", "message": "Request: POST /assist - Time: 0.4941s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T17:33:18.197032", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T17:33:19.647420", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T17:33:19.647609", "level": "INFO", "message": "Request: POST /assist - Time: 1.4513s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T17:33:30.952263", "level": "INFO", "message": "Successful login for user: testuser", "module": "main", "function": "login_for_access_token", "line": 287}
{"timestamp": "2025-04-24T17:33:30.952886", "level": "INFO", "message": "Request: POST /token - Time: 0.2307s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T17:37:40.560540", "level": "INFO", "message": "Successful login for user: testuser", "module": "main", "function": "login_for_access_token", "line": 287}
{"timestamp": "2025-04-24T17:37:40.561792", "level": "INFO", "message": "Request: POST /token - Time: 0.2508s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T17:53:55.331525", "level": "INFO", "message": "Successful login for user: testuser", "module": "main", "function": "login_for_access_token", "line": 287}
{"timestamp": "2025-04-24T17:53:55.332820", "level": "INFO", "message": "Request: POST /token - Time: 0.2573s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T17:57:15.176060", "level": "INFO", "message": "Successful login for user: testuser", "module": "main", "function": "login_for_access_token", "line": 287}
{"timestamp": "2025-04-24T17:57:15.177714", "level": "INFO", "message": "Request: POST /token - Time: 0.2458s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T17:57:37.386231", "level": "WARNING", "message": "Failed login attempt for user: testuser", "module": "main", "function": "login_for_access_token", "line": 280}
{"timestamp": "2025-04-24T17:57:37.386535", "level": "INFO", "message": "Request: POST /token - Time: 0.2545s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T17:58:57.779189", "level": "WARNING", "message": "Failed login attempt for user: testuser", "module": "main", "function": "login_for_access_token", "line": 280}
{"timestamp": "2025-04-24T17:58:57.779523", "level": "INFO", "message": "Request: POST /token - Time: 0.2439s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T17:59:06.731435", "level": "INFO", "message": "Successful login for user: testuser", "module": "main", "function": "login_for_access_token", "line": 287}
{"timestamp": "2025-04-24T17:59:06.731974", "level": "INFO", "message": "Request: POST /token - Time: 0.2322s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T18:16:30.771996", "level": "INFO", "message": "Successful login for user: testuser", "module": "main", "function": "login_for_access_token", "line": 287}
{"timestamp": "2025-04-24T18:16:30.772310", "level": "INFO", "message": "Request: POST /token - Time: 0.2468s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T18:35:42.116440", "level": "INFO", "message": "Successful login for user: testuser", "module": "main", "function": "login_for_access_token", "line": 287}
{"timestamp": "2025-04-24T18:35:42.117959", "level": "INFO", "message": "Request: POST /token - Time: 0.2321s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T18:48:28.388818", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 227}
{"timestamp": "2025-04-24T18:48:28.389032", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 229}
{"timestamp": "2025-04-24T18:48:29.028186", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 222}
{"timestamp": "2025-04-24T18:56:30.237181", "level": "INFO", "message": "Successful login for user: testuser", "module": "main", "function": "login_for_access_token", "line": 288}
{"timestamp": "2025-04-24T18:56:30.237765", "level": "INFO", "message": "Request: POST /token - Time: 0.2368s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T18:57:04.096675", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T18:57:04.750137", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T18:57:04.750394", "level": "INFO", "message": "Request: POST /assist - Time: 0.6553s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T18:57:19.185747", "level": "INFO", "message": "Request received", "module": "logger", "function": "log_request", "line": 74}
{"timestamp": "2025-04-24T18:57:22.057425", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-24T18:57:22.057686", "level": "INFO", "message": "Request: POST /assist - Time: 2.8729s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T18:58:30.155479", "level": "INFO", "message": "Successful login for user: testuser", "module": "main", "function": "login_for_access_token", "line": 288}
{"timestamp": "2025-04-24T18:58:30.156038", "level": "INFO", "message": "Request: POST /token - Time: 0.2565s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T18:58:36.740943", "level": "INFO", "message": "Successful login for user: testuser", "module": "main", "function": "login_for_access_token", "line": 288}
{"timestamp": "2025-04-24T18:58:36.741291", "level": "INFO", "message": "Request: POST /token - Time: 0.2453s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T18:58:54.360380", "level": "INFO", "message": "Successful login for user: testuser", "module": "main", "function": "login_for_access_token", "line": 288}
{"timestamp": "2025-04-24T18:58:54.360718", "level": "INFO", "message": "Request: POST /token - Time: 0.2566s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T18:59:50.408798", "level": "INFO", "message": "Successful login for user: testuser", "module": "main", "function": "login_for_access_token", "line": 288}
{"timestamp": "2025-04-24T18:59:50.409096", "level": "INFO", "message": "Request: POST /token - Time: 0.2364s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T19:03:06.426359", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 228}
{"timestamp": "2025-04-24T19:03:06.426859", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 230}
{"timestamp": "2025-04-24T21:34:47.809656", "level": "INFO", "message": "Starting LLM Assistant API on 0.0.0.0:8000", "module": "main", "function": "<module>", "line": 555}
{"timestamp": "2025-04-24T21:34:48.445090", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 222}
{"timestamp": "2025-04-24T21:35:53.002680", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 228}
{"timestamp": "2025-04-24T21:35:53.009034", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 230}
{"timestamp": "2025-04-24T21:35:53.691665", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 222}
{"timestamp": "2025-04-24T21:51:20.599136", "level": "INFO", "message": "Request: POST /api/assist - Time: 0.0021s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T21:51:35.818351", "level": "INFO", "message": "Request: POST /api/assist - Time: 0.0006s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-24T21:51:47.472749", "level": "INFO", "message": "Request: POST /api/assist - Time: 0.0008s", "module": "main", "function": "__call__", "line": 153}
{"timestamp": "2025-04-27T20:47:34.698858", "level": "INFO", "message": "Starting LLM Assistant API on 0.0.0.0:8000", "module": "main", "function": "<module>", "line": 555}
{"timestamp": "2025-04-27T20:47:35.329208", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 222}
{"timestamp": "2025-04-27T21:00:58.832340", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 228}
{"timestamp": "2025-04-27T21:00:58.836071", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 230}
{"timestamp": "2025-04-27T21:00:59.368155", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 222}
{"timestamp": "2025-04-27T21:00:59.479510", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 222}
{"timestamp": "2025-04-27T21:01:06.745322", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 228}
{"timestamp": "2025-04-27T21:01:06.747600", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 230}
{"timestamp": "2025-04-27T21:01:06.753741", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 228}
{"timestamp": "2025-04-27T21:01:06.756183", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 230}
{"timestamp": "2025-04-27T21:01:47.154782", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 226}
{"timestamp": "2025-04-27T21:39:24.130441", "level": "INFO", "message": "Starting LLM Assistant API on 0.0.0.0:8000", "module": "main", "function": "<module>", "line": 559}
{"timestamp": "2025-04-27T21:39:24.773431", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 226}
{"timestamp": "2025-04-27T21:46:03.663842", "level": "INFO", "message": "Request: GET /llm-test - Time: 0.0010s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-27T21:46:13.520795", "level": "INFO", "message": "Request: POST /assist - Time: 0.0007s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-27T21:46:33.052678", "level": "INFO", "message": "Request: POST /token - Time: 0.0027s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-27T21:46:38.380104", "level": "WARNING", "message": "Failed login attempt for user: admin", "module": "main", "function": "login_for_access_token", "line": 285}
{"timestamp": "2025-04-27T21:46:38.380311", "level": "INFO", "message": "Request: POST /token - Time: 0.0015s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-27T21:48:49.362760", "level": "INFO", "message": "Request: GET /llm-test - Time: 0.0003s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-27T21:51:23.189087", "level": "INFO", "message": "Request: POST /assist - Time: 0.0006s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-27T22:00:04.194500", "level": "INFO", "message": "Request: POST /assist - Time: 0.0006s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-27T22:02:31.100690", "level": "INFO", "message": "Request: POST /assist - Time: 0.0005s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-27T22:03:13.948689", "level": "INFO", "message": "Request: POST /assist - Time: 0.0005s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-27T22:05:11.671854", "level": "INFO", "message": "Starting LLM Assistant API on 0.0.0.0:8000", "module": "main", "function": "<module>", "line": 559}
{"timestamp": "2025-04-27T22:05:12.304830", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 226}
{"timestamp": "2025-04-27T22:10:08.752195", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 226}
{"timestamp": "2025-04-27T22:11:09.172301", "level": "INFO", "message": "Request: GET /docs - Time: 0.0007s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-27T22:11:09.199985", "level": "INFO", "message": "Request: GET /favicon.ico - Time: 0.0003s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-27T22:12:51.188272", "level": "INFO", "message": "Successful login for user: testuser", "module": "main", "function": "login_for_access_token", "line": 292}
{"timestamp": "2025-04-27T22:12:51.196508", "level": "INFO", "message": "Request: POST /token - Time: 0.2514s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-27T22:12:57.079053", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-27T22:12:57.081125", "level": "INFO", "message": "Request: POST /assist - Time: 0.5494s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-27T22:13:55.457606", "level": "INFO", "message": "Request: POST /assist - Time: 0.0004s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-27T22:15:39.973620", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 232}
{"timestamp": "2025-04-27T22:15:39.973925", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 234}
{"timestamp": "2025-04-27T22:16:00.447824", "level": "INFO", "message": "Starting LLM Assistant API on 0.0.0.0:8000", "module": "main", "function": "<module>", "line": 559}
{"timestamp": "2025-04-27T22:16:01.075995", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 226}
{"timestamp": "2025-04-27T22:20:03.556967", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 226}
{"timestamp": "2025-04-27T22:20:36.188880", "level": "INFO", "message": "Request: POST /assist - Time: 0.0005s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-27T22:20:51.520767", "level": "INFO", "message": "Request: POST /assist - Time: 0.0006s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-27T22:25:58.747977", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 232}
{"timestamp": "2025-04-27T22:25:58.748158", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 234}
{"timestamp": "2025-04-27T22:26:05.682640", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 226}
{"timestamp": "2025-04-27T22:27:39.851484", "level": "INFO", "message": "Successful login for user: testuser", "module": "main", "function": "login_for_access_token", "line": 292}
{"timestamp": "2025-04-27T22:27:39.854719", "level": "INFO", "message": "Request: POST /token - Time: 0.2545s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-27T22:28:19.272982", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 226}
{"timestamp": "2025-04-27T22:29:24.307330", "level": "INFO", "message": "Successful login for user: testuser", "module": "main", "function": "login_for_access_token", "line": 292}
{"timestamp": "2025-04-27T22:29:24.310765", "level": "INFO", "message": "Request: POST /token - Time: 0.2479s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-27T22:29:38.194743", "level": "INFO", "message": "Request: POST /assist - Time: 0.0007s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-27T22:29:38.584841", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-27T22:29:38.585485", "level": "INFO", "message": "Request: POST /assist - Time: 0.3812s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-27T22:29:58.346030", "level": "INFO", "message": "Request: POST /assist - Time: 0.0007s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-27T22:29:58.354534", "level": "INFO", "message": "Request: POST /assist - Time: 0.0005s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-27T22:43:49.989778", "level": "INFO", "message": "Request: POST /assist - Time: 0.0005s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-27T22:45:07.475915", "level": "INFO", "message": "Request: POST /assist - Time: 0.0005s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-27T22:45:26.944929", "level": "INFO", "message": "Request: POST /assist - Time: 0.0004s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-27T23:01:33.346479", "level": "INFO", "message": "Starting LLM Assistant API on 0.0.0.0:8000", "module": "main", "function": "<module>", "line": 559}
{"timestamp": "2025-04-27T23:01:34.025844", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 226}
{"timestamp": "2025-04-27T23:04:27.995382", "level": "INFO", "message": "Starting LLM Assistant API on 0.0.0.0:8000", "module": "main", "function": "<module>", "line": 559}
{"timestamp": "2025-04-27T23:04:37.045785", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 232}
{"timestamp": "2025-04-27T23:04:37.049314", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 234}
{"timestamp": "2025-04-27T23:04:37.687905", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 226}
{"timestamp": "2025-04-27T23:04:42.773506", "level": "INFO", "message": "Starting LLM Assistant API on 0.0.0.0:8001", "module": "main", "function": "<module>", "line": 559}
{"timestamp": "2025-04-27T23:04:43.415917", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 226}
{"timestamp": "2025-04-27T23:04:55.046862", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 232}
{"timestamp": "2025-04-27T23:04:55.049869", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 234}
{"timestamp": "2025-04-27T23:04:55.062112", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 232}
{"timestamp": "2025-04-27T23:04:55.064648", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 234}
{"timestamp": "2025-04-27T23:04:55.700931", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 226}
{"timestamp": "2025-04-27T23:04:55.706393", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 226}
{"timestamp": "2025-04-27T23:05:04.150273", "level": "INFO", "message": "Successful login for user: testuser", "module": "main", "function": "login_for_access_token", "line": 292}
{"timestamp": "2025-04-27T23:05:04.152600", "level": "INFO", "message": "Request: POST /token - Time: 0.2534s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-27T23:10:53.677645", "level": "INFO", "message": "Starting LLM Assistant API on 0.0.0.0:8001", "module": "main", "function": "<module>", "line": 559}
{"timestamp": "2025-04-27T23:11:32.377128", "level": "INFO", "message": "Successful login for user: testuser", "module": "main", "function": "login_for_access_token", "line": 292}
{"timestamp": "2025-04-27T23:11:32.377756", "level": "INFO", "message": "Request: POST /token - Time: 0.2439s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-27T23:13:40.868616", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-27T23:13:40.869137", "level": "INFO", "message": "Request: POST /assist - Time: 0.3431s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-27T23:13:48.895744", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-27T23:13:48.896582", "level": "INFO", "message": "Request: POST /assist - Time: 0.5532s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-27T23:14:00.465193", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-27T23:14:00.466049", "level": "INFO", "message": "Request: POST /assist - Time: 0.7857s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-27T23:14:10.314702", "level": "INFO", "message": "Request: POST /assist - Time: 0.0005s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-27T23:14:48.166521", "level": "INFO", "message": "Request: POST /assist - Time: 0.0004s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-27T23:15:00.219241", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-27T23:15:00.219626", "level": "INFO", "message": "Request: POST /assist - Time: 0.7110s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-27T23:16:39.273194", "level": "INFO", "message": "Request: GET /health - Time: 0.0002s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-27T23:16:47.882727", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 232}
{"timestamp": "2025-04-27T23:16:47.882925", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 234}
{"timestamp": "2025-04-27T23:16:53.769845", "level": "INFO", "message": "Starting LLM Assistant API on 0.0.0.0:8001", "module": "main", "function": "<module>", "line": 559}
{"timestamp": "2025-04-27T23:16:54.399610", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 226}
{"timestamp": "2025-04-28T03:43:34.948765", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 226}
{"timestamp": "2025-04-28T03:47:55.638162", "level": "INFO", "message": "Request: POST /token - Time: 0.0012s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T03:48:09.897267", "level": "INFO", "message": "Successful login for user: testuser", "module": "main", "function": "login_for_access_token", "line": 292}
{"timestamp": "2025-04-28T03:48:09.899628", "level": "INFO", "message": "Request: POST /token - Time: 0.2639s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T03:48:25.252092", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-28T03:48:25.252628", "level": "INFO", "message": "Request: POST /assist - Time: 0.4445s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T03:48:41.907397", "level": "INFO", "message": "Summary generated via LLMClient.", "module": "summarize", "function": "process", "line": 86}
{"timestamp": "2025-04-28T03:48:41.907605", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-28T03:48:41.907845", "level": "INFO", "message": "Request: POST /assist - Time: 0.3876s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T03:49:00.058303", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-28T03:49:00.058763", "level": "INFO", "message": "Request: POST /assist - Time: 0.9071s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T03:49:18.362305", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-28T03:49:18.362773", "level": "INFO", "message": "Request: POST /assist - Time: 0.8023s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T03:49:38.627080", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-28T03:49:38.627468", "level": "INFO", "message": "Request: POST /assist - Time: 0.3100s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T03:56:17.118799", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-28T03:56:17.119152", "level": "INFO", "message": "Request: POST /assist - Time: 0.8144s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T03:56:26.006396", "level": "INFO", "message": "Request: POST /api/email - Time: 0.0011s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T03:56:38.014170", "level": "INFO", "message": "Request: POST /api/code - Time: 0.0008s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T03:56:39.529459", "level": "INFO", "message": "Request: POST /api/code - Time: 0.0021s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T03:56:40.132187", "level": "INFO", "message": "Request: POST /api/code - Time: 0.0008s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T03:56:40.618769", "level": "INFO", "message": "Request: POST /api/code - Time: 0.0012s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T03:57:04.460089", "level": "INFO", "message": "Request: POST /api/email - Time: 0.0011s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T03:57:21.719920", "level": "INFO", "message": "Request: POST /api/email - Time: 0.0012s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T03:59:44.130514", "level": "INFO", "message": "Request: POST /assist - Time: 0.0004s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T03:59:51.040588", "level": "INFO", "message": "Request: POST /login - Time: 0.0002s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T03:59:57.535376", "level": "INFO", "message": "Request: GET / - Time: 0.0003s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T04:00:08.964767", "level": "INFO", "message": "Request: GET /docs - Time: 0.0002s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T04:03:44.222192", "level": "INFO", "message": "Request: POST /api/summarize - Time: 0.0012s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T04:04:03.835879", "level": "INFO", "message": "Request: POST /api/summarize - Time: 0.0007s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T04:05:57.965857", "level": "INFO", "message": "Request: POST /assist - Time: 0.0003s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T04:06:27.085839", "level": "INFO", "message": "Request: POST /api/email - Time: 0.0006s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T04:08:26.281455", "level": "INFO", "message": "Request: POST /todo - Time: 0.0003s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T04:08:47.705420", "level": "INFO", "message": "Request: POST /assist - Time: 0.0007s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T04:09:01.579163", "level": "INFO", "message": "Request: POST /assist - Time: 0.0004s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T04:09:05.619151", "level": "INFO", "message": "Request: GET /todos - Time: 0.0003s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T04:13:29.643068", "level": "INFO", "message": "Request: GET /todos - Time: 0.0002s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T04:13:52.171319", "level": "INFO", "message": "Request: GET /todos - Time: 0.0004s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T04:13:58.226028", "level": "ERROR", "message": "Error in api", "module": "logger", "function": "log_error", "line": 108, "exception": "  + Exception Group Traceback (most recent call last):\n  |   File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/_utils.py\", line 76, in collapse_excgroups\n  |     yield\n  |   File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 177, in __call__\n  |     async with anyio.create_task_group() as task_group:\n  |   File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 772, in __aexit__\n  |     raise BaseExceptionGroup(\n  | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\n  +-+---------------- 1 ----------------\n    | Traceback (most recent call last):\n    |   File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/middleware/errors.py\", line 165, in __call__\n    |     await self.app(scope, receive, _send)\n    |   File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/middleware/cors.py\", line 85, in __call__\n    |     await self.app(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/middleware/gzip.py\", line 29, in __call__\n    |     await responder(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/middleware/gzip.py\", line 126, in __call__\n    |     await super().__call__(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/middleware/gzip.py\", line 46, in __call__\n    |     await self.app(scope, receive, self.send_with_compression)\n    |   File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 176, in __call__\n    |     with recv_stream, send_stream, collapse_excgroups():\n    |   File \"/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/contextlib.py\", line 158, in __exit__\n    |     self.gen.throw(typ, value, traceback)\n    |   File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/_utils.py\", line 82, in collapse_excgroups\n    |     raise exc\n    |   File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 178, in __call__\n    |     response = await self.dispatch_func(request, call_next)\n    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/Users/simba/Downloads/Personal-AI-Agent/main.py\", line 149, in __call__\n    |     response = await call_next(request)\n    |                ^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 156, in call_next\n    |     raise app_exc\n    |   File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 141, in coro\n    |     await self.app(scope, receive_or_disconnect, send_no_error)\n    |   File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n    |     await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    |     raise exc\n    |   File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    |     await app(scope, receive, sender)\n    |   File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 714, in __call__\n    |     await self.middleware_stack(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 734, in app\n    |     await route.handle(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 288, in handle\n    |     await self.app(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 76, in app\n    |     await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    |     raise exc\n    |   File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    |     await app(scope, receive, sender)\n    |   File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 73, in app\n    |     response = await f(request)\n    |                ^^^^^^^^^^^^^^^^\n    |   File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/fastapi/routing.py\", line 301, in app\n    |     raw_response = await run_endpoint_function(\n    |                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/fastapi/routing.py\", line 212, in run_endpoint_function\n    |     return await dependant.call(**values)\n    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/Users/simba/Downloads/Personal-AI-Agent/main.py\", line 464, in add_todo\n    |     return await todo_service.add_task(current_user.username, task)\n    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/Users/simba/Downloads/Personal-AI-Agent/services/todo_manager.py\", line 129, in add_task\n    |     tags = tags or Task._parse_tags(title)\n    |                    ^^^^^^^^^^^^^^^^^^^^^^^\n    | TypeError: Task._parse_tags() missing 1 required positional argument: 'text'\n    +------------------------------------\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/middleware/errors.py\", line 165, in __call__\n    await self.app(scope, receive, _send)\n  File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/middleware/cors.py\", line 85, in __call__\n    await self.app(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/middleware/gzip.py\", line 29, in __call__\n    await responder(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/middleware/gzip.py\", line 126, in __call__\n    await super().__call__(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/middleware/gzip.py\", line 46, in __call__\n    await self.app(scope, receive, self.send_with_compression)\n  File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 176, in __call__\n    with recv_stream, send_stream, collapse_excgroups():\n  File \"/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/contextlib.py\", line 158, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/_utils.py\", line 82, in collapse_excgroups\n    raise exc\n  File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 178, in __call__\n    response = await self.dispatch_func(request, call_next)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/simba/Downloads/Personal-AI-Agent/main.py\", line 149, in __call__\n    response = await call_next(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 156, in call_next\n    raise app_exc\n  File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 141, in coro\n    await self.app(scope, receive_or_disconnect, send_no_error)\n  File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 714, in __call__\n    await self.middleware_stack(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 734, in app\n    await route.handle(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 288, in handle\n    await self.app(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 76, in app\n    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 73, in app\n    response = await f(request)\n               ^^^^^^^^^^^^^^^^\n  File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/fastapi/routing.py\", line 301, in app\n    raw_response = await run_endpoint_function(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/fastapi/routing.py\", line 212, in run_endpoint_function\n    return await dependant.call(**values)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/simba/Downloads/Personal-AI-Agent/main.py\", line 464, in add_todo\n    return await todo_service.add_task(current_user.username, task)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/simba/Downloads/Personal-AI-Agent/services/todo_manager.py\", line 129, in add_task\n    tags = tags or Task._parse_tags(title)\n                   ^^^^^^^^^^^^^^^^^^^^^^^\nTypeError: Task._parse_tags() missing 1 required positional argument: 'text'"}
{"timestamp": "2025-04-28T04:14:12.181509", "level": "INFO", "message": "Request: GET /todos - Time: 0.0010s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T04:14:43.031686", "level": "ERROR", "message": "Error in api", "module": "logger", "function": "log_error", "line": 108, "exception": "  + Exception Group Traceback (most recent call last):\n  |   File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/_utils.py\", line 76, in collapse_excgroups\n  |     yield\n  |   File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 177, in __call__\n  |     async with anyio.create_task_group() as task_group:\n  |   File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 772, in __aexit__\n  |     raise BaseExceptionGroup(\n  | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\n  +-+---------------- 1 ----------------\n    | Traceback (most recent call last):\n    |   File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/middleware/errors.py\", line 165, in __call__\n    |     await self.app(scope, receive, _send)\n    |   File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/middleware/cors.py\", line 85, in __call__\n    |     await self.app(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/middleware/gzip.py\", line 29, in __call__\n    |     await responder(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/middleware/gzip.py\", line 126, in __call__\n    |     await super().__call__(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/middleware/gzip.py\", line 46, in __call__\n    |     await self.app(scope, receive, self.send_with_compression)\n    |   File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 176, in __call__\n    |     with recv_stream, send_stream, collapse_excgroups():\n    |   File \"/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/contextlib.py\", line 158, in __exit__\n    |     self.gen.throw(typ, value, traceback)\n    |   File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/_utils.py\", line 82, in collapse_excgroups\n    |     raise exc\n    |   File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 178, in __call__\n    |     response = await self.dispatch_func(request, call_next)\n    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/Users/simba/Downloads/Personal-AI-Agent/main.py\", line 149, in __call__\n    |     response = await call_next(request)\n    |                ^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 156, in call_next\n    |     raise app_exc\n    |   File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 141, in coro\n    |     await self.app(scope, receive_or_disconnect, send_no_error)\n    |   File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n    |     await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    |     raise exc\n    |   File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    |     await app(scope, receive, sender)\n    |   File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 714, in __call__\n    |     await self.middleware_stack(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 734, in app\n    |     await route.handle(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 288, in handle\n    |     await self.app(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 76, in app\n    |     await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n    |   File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    |     raise exc\n    |   File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    |     await app(scope, receive, sender)\n    |   File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 73, in app\n    |     response = await f(request)\n    |                ^^^^^^^^^^^^^^^^\n    |   File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/fastapi/routing.py\", line 301, in app\n    |     raw_response = await run_endpoint_function(\n    |                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/fastapi/routing.py\", line 212, in run_endpoint_function\n    |     return await dependant.call(**values)\n    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/Users/simba/Downloads/Personal-AI-Agent/main.py\", line 464, in add_todo\n    |     return await todo_service.add_task(current_user.username, task)\n    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/Users/simba/Downloads/Personal-AI-Agent/services/todo_manager.py\", line 129, in add_task\n    |     tags = tags or Task._parse_tags(title)\n    |                    ^^^^^^^^^^^^^^^^^^^^^^^\n    | TypeError: Task._parse_tags() missing 1 required positional argument: 'text'\n    +------------------------------------\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/middleware/errors.py\", line 165, in __call__\n    await self.app(scope, receive, _send)\n  File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/middleware/cors.py\", line 85, in __call__\n    await self.app(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/middleware/gzip.py\", line 29, in __call__\n    await responder(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/middleware/gzip.py\", line 126, in __call__\n    await super().__call__(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/middleware/gzip.py\", line 46, in __call__\n    await self.app(scope, receive, self.send_with_compression)\n  File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 176, in __call__\n    with recv_stream, send_stream, collapse_excgroups():\n  File \"/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/contextlib.py\", line 158, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/_utils.py\", line 82, in collapse_excgroups\n    raise exc\n  File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 178, in __call__\n    response = await self.dispatch_func(request, call_next)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/simba/Downloads/Personal-AI-Agent/main.py\", line 149, in __call__\n    response = await call_next(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 156, in call_next\n    raise app_exc\n  File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 141, in coro\n    await self.app(scope, receive_or_disconnect, send_no_error)\n  File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 714, in __call__\n    await self.middleware_stack(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 734, in app\n    await route.handle(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 288, in handle\n    await self.app(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 76, in app\n    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n  File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 73, in app\n    response = await f(request)\n               ^^^^^^^^^^^^^^^^\n  File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/fastapi/routing.py\", line 301, in app\n    raw_response = await run_endpoint_function(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/simba/Downloads/Personal-AI-Agent/.venv/lib/python3.11/site-packages/fastapi/routing.py\", line 212, in run_endpoint_function\n    return await dependant.call(**values)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/simba/Downloads/Personal-AI-Agent/main.py\", line 464, in add_todo\n    return await todo_service.add_task(current_user.username, task)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/simba/Downloads/Personal-AI-Agent/services/todo_manager.py\", line 129, in add_task\n    tags = tags or Task._parse_tags(title)\n                   ^^^^^^^^^^^^^^^^^^^^^^^\nTypeError: Task._parse_tags() missing 1 required positional argument: 'text'"}
{"timestamp": "2025-04-28T04:39:37.989428", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-28T04:39:37.990026", "level": "INFO", "message": "Request: POST /assist - Time: 0.8394s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T04:39:43.554388", "level": "INFO", "message": "Request: POST /api/summarize - Time: 0.0008s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T04:40:02.357517", "level": "INFO", "message": "Request: POST /api/summarize - Time: 0.0008s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T04:40:17.999674", "level": "INFO", "message": "Request: POST /api/summarize - Time: 0.0017s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T04:40:18.979941", "level": "INFO", "message": "Request: POST /api/summarize - Time: 0.0007s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T04:40:19.898824", "level": "INFO", "message": "Request: POST /api/summarize - Time: 0.0010s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T04:40:32.302016", "level": "INFO", "message": "Request: POST /api/summarize - Time: 0.0007s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T04:40:48.225217", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-28T04:40:48.225848", "level": "INFO", "message": "Request: POST /assist - Time: 3.9314s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T04:41:41.876150", "level": "INFO", "message": "Request: POST /api/code - Time: 0.0009s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T04:42:04.957174", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-28T04:42:04.957947", "level": "INFO", "message": "Request: POST /assist - Time: 0.7016s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T04:42:31.525282", "level": "INFO", "message": "Request: POST /api/summarize - Time: 0.0008s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T04:43:10.060823", "level": "INFO", "message": "Request: POST /api/code - Time: 0.0010s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T04:46:49.108441", "level": "INFO", "message": "Request: POST /api/summarize - Time: 0.0007s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T04:47:22.803864", "level": "INFO", "message": "Request: POST /api/summarize - Time: 0.0006s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T04:47:30.604034", "level": "INFO", "message": "Request: POST /api/summarize - Time: 0.0007s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T04:48:24.907321", "level": "INFO", "message": "Request: POST /api/summarize - Time: 0.0007s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T04:56:22.605160", "level": "INFO", "message": "Request: POST /api/code - Time: 0.0009s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T04:58:15.789022", "level": "INFO", "message": "Request: POST /api/code - Time: 0.0020s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T04:59:03.280571", "level": "INFO", "message": "Request: POST /api/code - Time: 0.0009s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T05:10:22.192192", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-28T05:10:22.192807", "level": "INFO", "message": "Request: POST /assist - Time: 1.2684s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T05:10:34.119599", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-28T05:10:34.120104", "level": "INFO", "message": "Request: POST /assist - Time: 3.6994s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T05:22:19.192389", "level": "INFO", "message": "Request: POST /api/assist - Time: 0.0019s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T05:22:36.589487", "level": "INFO", "message": "Request: POST /assist - Time: 0.0021s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T05:22:55.136433", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-28T05:22:55.137304", "level": "INFO", "message": "Request: POST /assist - Time: 0.4388s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T05:29:55.419153", "level": "INFO", "message": "Request: POST /api/assist - Time: 0.0023s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T05:36:30.219536", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-28T05:36:30.220050", "level": "INFO", "message": "Request: POST /assist - Time: 0.6890s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T05:36:42.271997", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-28T05:36:42.276378", "level": "INFO", "message": "Request: POST /assist - Time: 0.5861s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T05:37:02.489236", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-28T05:37:02.489488", "level": "INFO", "message": "Request: POST /assist - Time: 1.1170s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T05:37:16.816590", "level": "INFO", "message": "Request: POST /assist - Time: 0.0030s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T05:37:40.118977", "level": "INFO", "message": "Request: POST /assist - Time: 0.0012s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T05:38:07.466345", "level": "INFO", "message": "Request: POST /assist - Time: 0.0020s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T05:43:46.964427", "level": "INFO", "message": "Summary generated via LLMClient.", "module": "summarize", "function": "process", "line": 86}
{"timestamp": "2025-04-28T05:43:46.964938", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-28T05:43:46.965686", "level": "INFO", "message": "Request: POST /assist - Time: 0.5213s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T05:43:58.757129", "level": "INFO", "message": "Summary generated via LLMClient.", "module": "summarize", "function": "process", "line": 86}
{"timestamp": "2025-04-28T05:43:58.757494", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-28T05:43:58.758109", "level": "INFO", "message": "Request: POST /assist - Time: 0.9824s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T05:54:51.771069", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-28T05:54:51.771898", "level": "INFO", "message": "Request: POST /assist - Time: 0.3469s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T05:54:56.888960", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-28T05:54:56.890561", "level": "INFO", "message": "Request: POST /assist - Time: 0.3513s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T05:55:00.066185", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-28T05:55:00.066744", "level": "INFO", "message": "Request: POST /assist - Time: 0.4855s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T05:55:07.339775", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-28T05:55:07.340212", "level": "INFO", "message": "Request: POST /assist - Time: 0.4065s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T05:55:19.421843", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-28T05:55:19.422881", "level": "INFO", "message": "Request: POST /assist - Time: 0.5511s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T05:55:39.549834", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-28T05:55:39.550379", "level": "INFO", "message": "Request: POST /assist - Time: 5.5857s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T06:08:40.418596", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-28T06:08:40.419010", "level": "INFO", "message": "Request: POST /assist - Time: 0.4129s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T06:08:47.921661", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-28T06:08:47.922188", "level": "INFO", "message": "Request: POST /assist - Time: 0.3258s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T06:09:02.084713", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-28T06:09:02.084934", "level": "INFO", "message": "Request: POST /assist - Time: 1.1155s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T06:09:09.543406", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-28T06:09:09.543652", "level": "INFO", "message": "Request: POST /assist - Time: 0.7284s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T15:57:58.788856", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 226}
{"timestamp": "2025-04-28T15:59:37.911426", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-28T15:59:37.912165", "level": "INFO", "message": "Request: POST /assist - Time: 6.7182s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T15:59:56.338835", "level": "INFO", "message": "Response sent", "module": "logger", "function": "log_response", "line": 91}
{"timestamp": "2025-04-28T15:59:56.339330", "level": "INFO", "message": "Request: POST /assist - Time: 3.6676s", "module": "main", "function": "__call__", "line": 157}
{"timestamp": "2025-04-28T16:04:10.825641", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 232}
{"timestamp": "2025-04-28T16:04:10.826330", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 234}
{"timestamp": "2025-04-28T16:04:11.484202", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 227}
{"timestamp": "2025-04-28T16:06:03.042224", "level": "INFO", "message": "Closing LLM client...", "module": "main", "function": "shutdown_event", "line": 233}
{"timestamp": "2025-04-28T16:06:03.045972", "level": "INFO", "message": "LLM client closed. Application shutting down.", "module": "main", "function": "shutdown_event", "line": 235}
{"timestamp": "2025-04-28T16:06:03.717289", "level": "INFO", "message": "\ud83d\ude80 Starting LLM Assistant API", "module": "main", "function": "startup_event", "line": 227}
